{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self attention\n",
    "class self_attention(nn.Module):\n",
    "    '''\n",
    "    Module to apply self attention to an input sequence of vectors\n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    emb_dim = dimension of the embedding vector\n",
    "    h = number of self attention heads\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, emb_dim, h):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.h = h\n",
    "        self.red_vec_size = emb_dim//h\n",
    "        \n",
    "        # Querry vector\n",
    "        self.WQ = nn.Linear(emb_dim, self.red_vec_size, bias = False)\n",
    "        self.WK = nn.Linear(emb_dim, self.red_vec_size, bias = False)\n",
    "        self.WV = nn.Linear(emb_dim, self.red_vec_size, bias = False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x has shape (batch_size, seq_len, emb_dim)\n",
    "        batch_size = x.shape[0]\n",
    "        seq_len = x.shape[1]\n",
    "        querries = self.WQ(x)\n",
    "        keys = self.WK(x)\n",
    "        values = self.WV(x)\n",
    "        att_scores = F.softmax(querries@keys.permute(0,2,1) \\\n",
    "                               /np.sqrt(self.red_vec_size), dim = 2)\n",
    "        ctx_vecs = att_scores @ values \n",
    "        assert ctx_vecs.shape == (batch_size, seq_len, self.red_vec_size ) \n",
    "        return querries, keys, values, att_scores, ctx_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "seq_len = 3\n",
    "emb_dim = 4\n",
    "h = 1\n",
    "x = torch.randn((batch_size, seq_len, emb_dim))\n",
    "attn = self_attention(emb_dim, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "self_attention(\n",
       "  (WQ): Linear(in_features=4, out_features=4, bias=False)\n",
       "  (WK): Linear(in_features=4, out_features=4, bias=False)\n",
       "  (WV): Linear(in_features=4, out_features=4, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "q , k, v, s, c = attn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3, 4]),\n",
       " torch.Size([5, 3, 4]),\n",
       " torch.Size([5, 3, 4]),\n",
       " torch.Size([5, 3, 3]),\n",
       " torch.Size([5, 3, 4]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape, k.shape, v.shape, s.shape, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = q[0,0]\n",
    "keys = k[0]\n",
    "values = v[0]\n",
    "ctx_vecs = c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0314, -0.3031,  0.8409,  0.1397], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3747, -1.2089, -0.1649,  0.8949],\n",
       "        [-0.0648,  1.3944,  0.3874,  0.3999],\n",
       "        [-0.0363, -0.1659,  0.1637, -0.6296]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0337,  0.0258,  0.1374], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1@keys.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3206, 0.3302, 0.3492], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrs = F.softmax(q1@keys.T/np.sqrt(4), dim = 0)\n",
    "scrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3206, 0.3302, 0.3492], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3206, 0.3302, 0.3492],\n",
       "         [0.2215, 0.5030, 0.2755],\n",
       "         [0.4110, 0.2363, 0.3527]],\n",
       "\n",
       "        [[0.3548, 0.3167, 0.3285],\n",
       "         [0.4189, 0.2568, 0.3243],\n",
       "         [0.3556, 0.3060, 0.3385]],\n",
       "\n",
       "        [[0.3155, 0.3380, 0.3465],\n",
       "         [0.2846, 0.4791, 0.2363],\n",
       "         [0.2929, 0.2040, 0.5032]],\n",
       "\n",
       "        [[0.3259, 0.3322, 0.3419],\n",
       "         [0.3451, 0.3391, 0.3158],\n",
       "         [0.3442, 0.3344, 0.3213]],\n",
       "\n",
       "        [[0.3278, 0.3273, 0.3448],\n",
       "         [0.3166, 0.5481, 0.1353],\n",
       "         [0.3095, 0.3506, 0.3399]]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(q@k.permute(0,2,1) /np.sqrt(4), dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1358, -0.0016, -0.1217, -0.0511], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrs@v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1358, -0.0016, -0.1217, -0.0511],\n",
       "        [ 0.0013,  0.3189, -0.2542, -0.0975],\n",
       "        [-0.2158, -0.2291, -0.0335, -0.0320]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1358, -0.0016, -0.1217, -0.0511],\n",
       "         [ 0.0013,  0.3189, -0.2542, -0.0975],\n",
       "         [-0.2158, -0.2291, -0.0335, -0.0320]],\n",
       "\n",
       "        [[ 0.8120, -0.0894,  0.7871,  0.5564],\n",
       "         [ 0.7608, -0.1372,  0.7545,  0.5095],\n",
       "         [ 0.7989, -0.0957,  0.7784,  0.5483]],\n",
       "\n",
       "        [[ 0.1582,  0.2911, -0.1662, -0.2523],\n",
       "         [-0.1341,  0.2950, -0.2876, -0.2172],\n",
       "         [ 0.4956,  0.2982, -0.0253, -0.2883]],\n",
       "\n",
       "        [[-0.2428, -0.4923, -0.0354, -0.2528],\n",
       "         [-0.2292, -0.5098, -0.0036, -0.2215],\n",
       "         [-0.2298, -0.5067, -0.0075, -0.2255]],\n",
       "\n",
       "        [[ 0.6654,  0.3321,  0.1367, -0.0468],\n",
       "         [ 0.9878,  0.5723,  0.1248, -0.1001],\n",
       "         [ 0.7042,  0.3354,  0.1583, -0.0388]]], grad_fn=<UnsafeViewBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn(x)[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_head_attn(nn.Module):\n",
    "    '''\n",
    "    Module to create multiple attention heads\n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    emb_dim = dimension of the embedding vectors\n",
    "    h = number of attention heads\n",
    "    parallelize = parallelize the computations for differnt heads \n",
    "    \n",
    "    '''\n",
    "    def __init__(self, emb_dim, h, p_drop = 0.1, parallelize = 'False'):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.h = h\n",
    "        self.red_vec_size = emb_dim // h \n",
    "        \n",
    "        self.heads = [self_attention(emb_dim, h) for i in range(h)]\n",
    "        \n",
    "        # transform the contatenated context vectors to have same size as emb_sim\n",
    "        # this is to be able to enable implement a skip-connection between the input and output\n",
    "        self.Wo = nn.Linear(self.red_vec_size*h, emb_dim, bias = False) \n",
    "        \n",
    "        # layer norm\n",
    "        # should we apply \n",
    "        self.LNorm = nn.LayerNorm(emb_dim)\n",
    "        \n",
    "        self.drop = nn.Dropout(p_drop)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ctx_vecs = torch.cat([head(x)[4] for head in self.heads], dim = 2)\n",
    "        transformed = self.drop(self.Wo(ctx_vecs))\n",
    "        \n",
    "        return self.LNorm(x + transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "seq_len = 3\n",
    "emb_dim = 6\n",
    "h = 2\n",
    "x = torch.randn((batch_size, seq_len, emb_dim))\n",
    "multihead = multi_head_attn(emb_dim, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = multihead(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 6])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-4.1064e-01, -1.3871e+00,  2.4360e-01, -8.5868e-01,  1.5224e+00,\n",
       "           8.9045e-01],\n",
       "         [-2.8164e-01, -3.8842e-01,  1.0994e-01,  1.8239e+00,  2.7160e-01,\n",
       "          -1.5354e+00],\n",
       "         [-5.3017e-01,  1.9463e+00,  6.5063e-01, -9.1471e-01, -6.3513e-01,\n",
       "          -5.1694e-01]],\n",
       "\n",
       "        [[-3.9618e-01, -1.2301e+00,  9.2241e-01, -9.1933e-01,  1.6228e+00,\n",
       "           3.5165e-04],\n",
       "         [-9.6310e-01,  1.8657e+00, -5.2858e-01,  6.0387e-01, -9.7342e-01,\n",
       "          -4.4662e-03],\n",
       "         [-6.3381e-01,  2.3347e-01,  5.1089e-01,  1.7669e+00, -1.3849e+00,\n",
       "          -4.9260e-01]],\n",
       "\n",
       "        [[ 1.3604e+00, -6.3797e-01, -1.6082e+00,  4.2927e-01, -4.3031e-01,\n",
       "           8.8678e-01],\n",
       "         [ 7.9993e-02,  1.1034e+00, -2.0039e+00, -9.8762e-02,  8.6470e-01,\n",
       "           5.4556e-02],\n",
       "         [-1.7524e+00,  5.1812e-01, -1.1487e-01, -4.1972e-01,  1.5578e+00,\n",
       "           2.1108e-01]],\n",
       "\n",
       "        [[ 2.0461e+00, -1.8943e-01,  2.6867e-01, -1.0729e+00, -5.3637e-01,\n",
       "          -5.1611e-01],\n",
       "         [-2.8147e-01, -1.2208e+00,  1.0317e+00,  8.0713e-01,  9.8448e-01,\n",
       "          -1.3210e+00],\n",
       "         [ 1.4274e+00, -8.4496e-01,  1.0756e+00, -1.4034e-01, -8.0577e-02,\n",
       "          -1.4371e+00]],\n",
       "\n",
       "        [[-1.5978e+00,  5.7749e-01, -3.7970e-01, -2.8189e-01,  1.6998e+00,\n",
       "          -1.7913e-02],\n",
       "         [-1.5885e+00,  7.4922e-01, -1.7347e-01, -9.4893e-01,  1.1554e+00,\n",
       "           8.0628e-01],\n",
       "         [-6.2031e-01,  4.3017e-01,  9.8901e-02, -7.2298e-01, -1.1039e+00,\n",
       "           1.9181e+00]]], grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "multi_head_attn(\n",
       "  (Wo): Linear(in_features=6, out_features=6, bias=False)\n",
       "  (LNorm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0.], requires_grad=True)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(multihead.LNorm.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.9671e-08, -1.9868e-08, -3.9736e-08],\n",
       "        [ 1.7191e-08, -3.8184e-08,  0.0000e+00],\n",
       "        [ 6.9539e-08, -1.1176e-08, -3.2286e-08],\n",
       "        [ 2.9802e-08,  1.9868e-08, -3.9736e-08],\n",
       "        [ 5.7742e-08,  1.9868e-08,  1.9868e-08]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx.mean(dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0954, 1.0954, 1.0954],\n",
       "        [1.0954, 1.0954, 1.0954],\n",
       "        [1.0954, 1.0954, 1.0954],\n",
       "        [1.0954, 1.0954, 1.0954],\n",
       "        [1.0954, 1.0954, 1.0954]], grad_fn=<StdBackward1>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx.std(dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder(nn.Module):\n",
    "    '''\n",
    "    The complete encoder module.\n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    emb_dim = dimension of the embedding vectors\n",
    "    h = number of attention heads\n",
    "    parallelize = parallelize the computations for differnt heads \n",
    "    ffn_l1_out_fts = number of out_features of 1st layer in feed forward NN. Default is 2048 a suggested in the original paper\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, emb_dim, h, p_drop = 0.1, parallelize = False, ffn_l1_out_fts = 2048 ):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.h = h\n",
    "        self.red_vec_size = emb_dim//h\n",
    "        \n",
    "        # multi_head_attention sub-layer\n",
    "        self.mul_h_attn = multi_head_attn(emb_dim, h, parallelize)\n",
    "        \n",
    "        # feedforward sublayers\n",
    "        self.l1 = nn.Linear(emb_dim, ffn_l1_out_fts)\n",
    "        self.l2 = nn.Linear(ffn_l1_out_fts, emb_dim)\n",
    "        \n",
    "        # layer norm\n",
    "        self.LNorm = nn.LayerNorm(emb_dim) \n",
    "        \n",
    "        self.drop = nn.Dropout(p_drop)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ctx_vecs = self.mul_h_attn(x)\n",
    "        out = torch.relu(self.l1(ctx_vecs))\n",
    "        out = self.drop(self.l2(out))\n",
    "        \n",
    "        return self.LNorm(out + ctx_vecs)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "seq_len = 3\n",
    "emb_dim = 6\n",
    "h = 2\n",
    "x = torch.randn((batch_size, seq_len, emb_dim))\n",
    "enc = encoder(emb_dim, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encoder(\n",
       "  (mul_h_attn): multi_head_attn(\n",
       "    (Wo): Linear(in_features=6, out_features=6, bias=False)\n",
       "    (LNorm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "    (drop): Dropout(p=False, inplace=False)\n",
       "  )\n",
       "  (l1): Linear(in_features=6, out_features=2048, bias=True)\n",
       "  (l2): Linear(in_features=2048, out_features=6, bias=True)\n",
       "  (LNorm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3483,  1.5321, -0.0805,  0.9615, -0.9427, -0.1222],\n",
       "         [-1.1032,  1.8091, -0.8596, -0.5028,  0.7174, -0.0608],\n",
       "         [ 0.8576,  0.6228,  0.2322,  0.6980, -2.0508, -0.3598]],\n",
       "\n",
       "        [[ 1.0219, -0.7204, -0.3305,  1.6504, -0.4307, -1.1908],\n",
       "         [-0.6353, -0.5219,  1.8023, -0.3116, -1.1473,  0.8138],\n",
       "         [-0.2948, -0.5906,  1.7865, -0.9642,  0.8804, -0.8172]],\n",
       "\n",
       "        [[ 1.8316, -0.9084,  0.4448, -0.6114,  0.3153, -1.0719],\n",
       "         [ 1.5792, -1.3215, -0.6016,  0.4079, -0.8161,  0.7521],\n",
       "         [-0.8307,  0.0321,  0.3367,  1.0778, -1.6943,  1.0785]],\n",
       "\n",
       "        [[-1.4939, -0.7144,  0.8934,  1.0832, -0.6777,  0.9095],\n",
       "         [ 1.4566, -1.1226, -0.3464,  1.2756, -0.8229, -0.4404],\n",
       "         [ 0.8849,  1.0277, -0.0203,  0.5917, -1.8441, -0.6399]],\n",
       "\n",
       "        [[-0.8583, -0.3137,  1.9140, -0.0414,  0.4415, -1.1422],\n",
       "         [-0.9590, -1.2817, -0.3318,  0.8109,  0.1330,  1.6286],\n",
       "         [-1.2759,  0.3068, -1.2981,  0.2983,  0.4527,  1.5162]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_out = enc(x)\n",
    "enc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 6])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 6])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder_decoder_attention(nn.Module):\n",
    "    '''\n",
    "    Module to implement the encoder_decoder attention layer. \n",
    "    This is same as the self_attention layer except that it takes two input vectors: \n",
    "                 1)encoder's final output \n",
    "                 2) output from previous decoder layer\n",
    "    The querries are generated from the previous decoder layer's output\n",
    "    The keys and the values are generated from the encoder's output \n",
    "         \n",
    "    '''\n",
    "    def __init__(self, emb_dim, h):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb_dim = emb_dim\n",
    "        self.h = h\n",
    "        self.red_vec_size = emb_dim//h\n",
    "        \n",
    "        # Querry vector\n",
    "        self.WQ = nn.Linear(emb_dim, self.red_vec_size, bias = False)\n",
    "        # Key vector\n",
    "        self.WK = nn.Linear(emb_dim, self.red_vec_size, bias = False)\n",
    "        # Value vector\n",
    "        self.WV = nn.Linear(emb_dim, self.red_vec_size, bias = False)\n",
    "        \n",
    "    def forward(self, enc_out, dec_out):\n",
    "        # x has shape (batch_size, seq_len, emb_dim)\n",
    "        batch_size = enc_out.shape[0]\n",
    "        seq_len = dec_out.shape[1] \n",
    "        querries = self.WQ(dec_out)\n",
    "        keys = self.WK(enc_out)\n",
    "        values = self.WV(enc_out)\n",
    "        att_scores = F.softmax((querries@keys.permute(0,2,1))\\\n",
    "                               /np.sqrt(self.red_vec_size), dim = 2)\n",
    "        ctx_vecs = att_scores @ values \n",
    "        assert ctx_vecs.shape == (batch_size, seq_len, self.red_vec_size ) \n",
    "        return querries, keys, values, att_scores, ctx_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encoder_decoder_attention(\n",
       "  (WQ): Linear(in_features=6, out_features=3, bias=False)\n",
       "  (WK): Linear(in_features=6, out_features=3, bias=False)\n",
       "  (WV): Linear(in_features=6, out_features=3, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "seq_len = 4\n",
    "emb_dim = 6\n",
    "h = 2\n",
    "enc_out = torch.randn((batch_size, seq_len, emb_dim))\n",
    "dec_out = torch.randn(batch_size, seq_len, emb_dim)\n",
    "enc_dec_attn = encoder_decoder_attention(emb_dim, h)\n",
    "enc_dec_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "q, k, v, s, c = enc_dec_attn(enc_out, dec_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4, 3]),\n",
       " torch.Size([5, 4, 3]),\n",
       " torch.Size([5, 4, 3]),\n",
       " torch.Size([5, 4, 4]),\n",
       " torch.Size([5, 4, 3]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape, k.shape, v.shape, s.shape, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1029,  0.1186, -0.0044], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = q[0,0]\n",
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = k[0]\n",
    "keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0756, -0.1248,  0.0227, -0.1537], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1@keys.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0756, -0.1248,  0.0227, -0.1537],\n",
       "         [ 0.0872,  0.0409,  0.0299, -0.4761],\n",
       "         [-0.0154,  0.4713, -0.0894, -0.3468],\n",
       "         [ 0.4081, -0.4477,  0.1143, -1.1486]],\n",
       "\n",
       "        [[-0.0164, -0.2652, -0.1197, -0.1430],\n",
       "         [ 0.0401, -0.0363,  0.1068,  0.1958],\n",
       "         [ 0.1085,  0.2425,  0.0118,  0.6188],\n",
       "         [-0.1510, -0.5897, -0.8944, -0.8882]],\n",
       "\n",
       "        [[ 0.3709,  0.0055, -0.0772, -0.3590],\n",
       "         [ 1.5343, -0.1651, -0.1205, -3.1556],\n",
       "         [-0.7267, -0.2349,  0.0049,  0.7369],\n",
       "         [ 0.3168, -0.0300,  0.0682, -1.1303]],\n",
       "\n",
       "        [[-0.5617,  0.6682, -0.5460,  0.3957],\n",
       "         [-0.4537,  0.4233, -0.3995,  0.2854],\n",
       "         [ 0.4149, -0.4033,  0.3639, -0.2499],\n",
       "         [-0.6814,  0.6980, -0.6365,  0.4783]],\n",
       "\n",
       "        [[-0.1548, -0.4114,  0.2064, -0.2677],\n",
       "         [ 0.2737,  0.7620, -0.6614,  0.4494],\n",
       "         [ 0.8711, -0.3750,  0.4456, -0.2468],\n",
       "         [-0.6290,  0.0325, -0.1076,  0.0350]]], grad_fn=<UnsafeViewBackward>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q @ k.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0756,  0.0872, -0.0154,  0.4081],\n",
       "         [-0.1248,  0.0409,  0.4713, -0.4477],\n",
       "         [ 0.0227,  0.0299, -0.0894,  0.1143],\n",
       "         [-0.1537, -0.4761, -0.3468, -1.1486]],\n",
       "\n",
       "        [[-0.0164,  0.0401,  0.1085, -0.1510],\n",
       "         [-0.2652, -0.0363,  0.2425, -0.5897],\n",
       "         [-0.1197,  0.1068,  0.0118, -0.8944],\n",
       "         [-0.1430,  0.1958,  0.6188, -0.8882]],\n",
       "\n",
       "        [[ 0.3709,  1.5343, -0.7267,  0.3168],\n",
       "         [ 0.0055, -0.1651, -0.2349, -0.0300],\n",
       "         [-0.0772, -0.1205,  0.0049,  0.0682],\n",
       "         [-0.3590, -3.1556,  0.7369, -1.1303]],\n",
       "\n",
       "        [[-0.5617, -0.4537,  0.4149, -0.6814],\n",
       "         [ 0.6682,  0.4233, -0.4033,  0.6980],\n",
       "         [-0.5460, -0.3995,  0.3639, -0.6365],\n",
       "         [ 0.3957,  0.2854, -0.2499,  0.4783]],\n",
       "\n",
       "        [[-0.1548,  0.2737,  0.8711, -0.6290],\n",
       "         [-0.4114,  0.7620, -0.3750,  0.0325],\n",
       "         [ 0.2064, -0.6614,  0.4456, -0.1076],\n",
       "         [-0.2677,  0.4494, -0.2468,  0.0350]]], grad_fn=<PermuteBackward>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(q @ k.permute(0,2,1)).permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2676, 0.2384, 0.2596, 0.2344], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1 = F.softmax((q1@keys.T/np.sqrt(3)), dim = 0)\n",
    "scores1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2676, 0.2384, 0.2596, 0.2344],\n",
       "        [0.2730, 0.2658, 0.2641, 0.1972],\n",
       "        [0.2434, 0.3224, 0.2332, 0.2010],\n",
       "        [0.3495, 0.2132, 0.2950, 0.1423]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2467, -0.2977, -0.3000],\n",
       "        [ 0.6025, -0.7979, -0.8116],\n",
       "        [ 0.0734,  0.4271,  0.9142],\n",
       "        [ 0.4020, -0.3414, -1.0237]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3230, -0.2391, -0.2764], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1 @ v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3230, -0.2391, -0.2764],\n",
       "        [ 0.3261, -0.2479, -0.2580],\n",
       "        [ 0.3522, -0.2987, -0.3272],\n",
       "        [ 0.2936, -0.1968, -0.1539]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4497, -0.1251, -0.5427], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2 = q[0,1]\n",
    "q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2730, 0.2658, 0.2641, 0.1972], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores2 = F.softmax((q2@keys.T/np.sqrt(3)), dim = 0)\n",
    "scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3261, -0.2479, -0.2580], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores2@v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1543, -0.0446,  0.3303], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq1 = q[1,0]\n",
    "keys = k[1]\n",
    "scores = F.softmax((qq1@keys.T/np.sqrt(3)), dim = 0)\n",
    "scores@v[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1543, -0.0446,  0.3303],\n",
       "        [-0.1581, -0.0394,  0.3407],\n",
       "        [-0.1663, -0.0300,  0.3654],\n",
       "        [-0.1463, -0.0492,  0.3323]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_head_enc_dec_attn(nn.Module):\n",
    "    def __init__(self, emb_dim, h, p_drop = 0.1):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.h = h\n",
    "        self.red_vec_size = emb_dim // h \n",
    "        \n",
    "        self.heads = [encoder_decoder_attention(emb_dim, h) for i in range(h)]\n",
    "        \n",
    "        # transform the contatenated context vectors to have same size as emb_sim\n",
    "        # this is to be able to enable implement a skip-connection between the input and output\n",
    "        self.Wo = nn.Linear(self.red_vec_size*h, emb_dim, bias = False) \n",
    "        \n",
    "        # layer norm\n",
    "        # should we apply \n",
    "        self.LNorm = nn.LayerNorm(emb_dim)\n",
    "        self.drop = nn.Dropout(p_drop)\n",
    "        \n",
    "    def forward(self, enc_out, dec_out):\n",
    "        ctx_vecs = torch.cat([head(enc_out, dec_out)[4] for head in self.heads], dim = 2)\n",
    "        transformed = self.drop(self.Wo(ctx_vecs))\n",
    "        \n",
    "        return self.LNorm(dec_out + transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "multi_head_enc_dec_attn(\n",
       "  (Wo): Linear(in_features=6, out_features=7, bias=False)\n",
       "  (LNorm): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "seq_len = 4\n",
    "emb_dim = 7\n",
    "h = 2\n",
    "enc_out = torch.randn((batch_size, seq_len, emb_dim))\n",
    "dec_out = torch.randn(batch_size, seq_len, emb_dim)\n",
    "enc_dec_attn = multi_head_enc_dec_attn(emb_dim, h)\n",
    "enc_dec_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = enc_dec_attn(enc_out, dec_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 7])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "multi_head_enc_dec_attn(\n",
       "  (Wo): Linear(in_features=6, out_features=7, bias=False)\n",
       "  (LNorm): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "enc_seq_len = 4\n",
    "dec_seq_len = 2\n",
    "emb_dim = 7\n",
    "h = 2\n",
    "enc_out = torch.randn((batch_size, enc_seq_len, emb_dim))\n",
    "dec_out = torch.randn(batch_size, dec_seq_len, emb_dim)\n",
    "enc_dec_attn = multi_head_enc_dec_attn(emb_dim, h)\n",
    "enc_dec_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1711, -1.1709,  1.0982, -0.2953,  0.3423,  0.4741, -1.6194],\n",
       "         [ 1.3957, -0.4433, -1.2028,  0.8868, -0.5694, -1.1050,  1.0379]],\n",
       "\n",
       "        [[-0.5090, -0.6015,  1.5085, -0.2069,  1.2823,  0.0790, -1.5525],\n",
       "         [-1.0828, -0.7441,  1.4600, -1.1130,  0.8267,  1.0360, -0.3829]],\n",
       "\n",
       "        [[ 1.2973, -1.6209,  0.9348,  0.7669,  0.1634, -0.8497, -0.6919],\n",
       "         [-2.0587,  0.3314,  0.3602,  1.5474, -0.2312,  0.2165, -0.1656]],\n",
       "\n",
       "        [[-0.0920,  0.9164,  0.8616,  1.2096, -0.5995, -0.4586, -1.8375],\n",
       "         [ 0.7972, -0.3917, -1.7374, -0.5560, -0.4122,  1.3338,  0.9665]],\n",
       "\n",
       "        [[ 0.1504,  0.9320, -2.0696,  1.0122,  0.7221, -0.3676, -0.3795],\n",
       "         [ 1.2064,  0.1238,  0.1759,  1.2276, -1.8877, -0.6101, -0.2359]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_dec_attn(enc_out, dec_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3487, -1.0080,  1.1054, -0.2318,  0.2958,  0.1564, -1.6664],\n",
       "         [ 1.3501, -0.2477, -0.9082,  0.8189, -0.7926, -1.3285,  1.1079]],\n",
       "\n",
       "        [[-0.1454, -1.0403,  1.0055,  0.2977,  1.5432, -0.1103, -1.5503],\n",
       "         [-0.8787, -1.1999,  1.1658, -0.7971,  1.2266,  1.0073, -0.5239]],\n",
       "\n",
       "        [[ 1.0944, -1.5910,  0.8559,  0.9670,  0.2592, -1.1665, -0.4190],\n",
       "         [-1.9486,  0.3670,  0.2123,  1.7130,  0.0643, -0.2329, -0.1751]],\n",
       "\n",
       "        [[-0.2817,  0.3685,  1.0967,  1.5727, -0.6840, -0.5392, -1.5330],\n",
       "         [ 0.4923, -1.1785, -1.3725,  0.1183, -0.5529,  1.0779,  1.4153]],\n",
       "\n",
       "        [[-0.1170,  1.6504, -1.9581,  0.0618,  0.4747,  0.2544, -0.3662],\n",
       "         [ 0.8939,  0.5020,  0.3712,  0.3950, -2.3384, -0.2046,  0.3809]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slfattn = multi_head_attn(emb_dim, h)\n",
    "slfattn(dec_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_out2 = torch.randn(batch_size, dec_seq_len+1, emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5686e+00, -8.6963e-01, -6.5939e-01,  7.1400e-01,  1.2092e+00,\n",
       "           1.1732e+00,  1.1657e-03],\n",
       "         [-1.6899e+00,  1.5516e+00, -8.7781e-01,  6.1185e-01,  1.1336e-01,\n",
       "          -3.7246e-01,  6.6343e-01],\n",
       "         [-3.7584e-01, -5.6523e-01,  4.9856e-01,  1.4796e+00,  1.0031e+00,\n",
       "          -1.7322e+00, -3.0804e-01]],\n",
       "\n",
       "        [[-2.0185e-01, -1.0596e+00,  1.5548e+00,  5.7128e-01,  7.8718e-01,\n",
       "          -1.5704e+00, -8.1464e-02],\n",
       "         [ 1.1978e+00,  4.9161e-01, -9.3503e-01, -1.1155e+00, -1.2132e+00,\n",
       "           2.9031e-01,  1.2841e+00],\n",
       "         [ 1.0718e+00,  7.8501e-01, -1.3154e+00, -8.7818e-01, -9.2953e-01,\n",
       "          -9.7484e-02,  1.3638e+00]],\n",
       "\n",
       "        [[-1.0263e+00,  1.3380e+00,  1.2605e+00, -1.2441e+00,  1.4385e-01,\n",
       "           4.3020e-01, -9.0221e-01],\n",
       "         [ 1.3033e+00, -1.5825e+00,  3.0695e-01, -1.5021e-01,  6.7714e-01,\n",
       "           7.3941e-01, -1.2941e+00],\n",
       "         [ 1.1351e+00, -6.0036e-01,  8.5821e-01,  9.8347e-01, -6.4763e-01,\n",
       "          -1.7954e+00,  6.6695e-02]],\n",
       "\n",
       "        [[ 1.2991e+00, -1.6254e-01,  1.6343e+00, -3.7056e-01, -1.4040e+00,\n",
       "          -4.2867e-01, -5.6763e-01],\n",
       "         [ 8.3377e-02, -1.1752e-01,  4.3260e-01,  1.3853e+00, -1.7459e+00,\n",
       "          -9.7395e-01,  9.3606e-01],\n",
       "         [-1.5837e+00,  3.7120e-01,  1.0904e+00,  1.3950e+00, -8.4279e-02,\n",
       "          -9.1525e-02, -1.0971e+00]],\n",
       "\n",
       "        [[ 3.2980e-02, -6.3734e-01,  5.0737e-02,  6.8286e-01, -1.8120e+00,\n",
       "           1.6854e+00, -2.6655e-03],\n",
       "         [ 6.1744e-01,  8.6791e-01, -5.8009e-01,  1.5532e+00, -4.9950e-01,\n",
       "          -2.9095e-01, -1.6680e+00],\n",
       "         [-8.6711e-01,  1.6378e+00,  1.2047e+00, -1.1127e+00, -4.4271e-01,\n",
       "           3.3412e-01, -7.5403e-01]]], grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slfattn(dec_out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder(nn.Module):\n",
    "    '''\n",
    "    The complete decoder module. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    emb_dim = dimension of the embedding vectors\n",
    "    h = number of attention heads\n",
    "    parallelize = parallelize the computations for differnt heads \n",
    "    ffn_l1_out_fts = number of out_features of 1st layer in feed forward NN. Default is 2048 a suggested in the original paper\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, emb_dim, h, p_drop = 0.1, parallelize = False, ffn_l1_out_fts = 2048):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb_dim = emb_dim\n",
    "        self.h = h\n",
    "        self.red_vec_size = emb_dim//h\n",
    "        \n",
    "        # multi_head_attention sub-layer\n",
    "        self.mul_h_attn = multi_head_attn(emb_dim, h, parallelize)\n",
    "        \n",
    "        # multi head encoder decoder attention sublayer\n",
    "        self.mul_h_enc_dec_attn = multi_head_enc_dec_attn(emb_dim, h)\n",
    "        \n",
    "        # feedforward sublayers\n",
    "        self.l1 = nn.Linear(emb_dim, ffn_l1_out_fts)\n",
    "        self.l2 = nn.Linear(ffn_l1_out_fts, emb_dim)\n",
    "        \n",
    "        # layer norm\n",
    "        self.LNorm = nn.LayerNorm(emb_dim) \n",
    "        \n",
    "        self.drop = nn.Dropout(p_drop)\n",
    "        \n",
    "    def forward(self, enc_vecs, dec_vecs):\n",
    "        dec_vecs = self.mul_h_attn(dec_vecs)\n",
    "        ff_in = self.mul_h_enc_dec_attn(enc_vecs, dec_vecs)\n",
    "        out = torch.relu(self.l1(ff_in))\n",
    "        out = self.drop(self.l2(out))\n",
    "        \n",
    "        return self.LNorm(out + ff_in)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decoder(\n",
       "  (mul_h_attn): multi_head_attn(\n",
       "    (Wo): Linear(in_features=6, out_features=7, bias=False)\n",
       "    (LNorm): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       "    (drop): Dropout(p=False, inplace=False)\n",
       "  )\n",
       "  (mul_h_enc_dec_attn): multi_head_enc_dec_attn(\n",
       "    (Wo): Linear(in_features=6, out_features=7, bias=False)\n",
       "    (LNorm): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (l1): Linear(in_features=7, out_features=2048, bias=True)\n",
       "  (l2): Linear(in_features=2048, out_features=7, bias=True)\n",
       "  (LNorm): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "enc_seq_len = 4\n",
    "dec_seq_len = 2\n",
    "emb_dim = 7\n",
    "h = 2\n",
    "enc_out = torch.randn((batch_size, enc_seq_len, emb_dim))\n",
    "dec_out = torch.randn(batch_size, dec_seq_len, emb_dim)\n",
    "dec = decoder(emb_dim, h)\n",
    "dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 7])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_ot = dec(enc_out, dec_out)\n",
    "dec_ot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 7])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(emb_dim, seq_len):\n",
    "    posts = torch.arange(seq_len).unsqueeze(1)\n",
    "    pows = 10000**(torch.arange(emb_dim//2)/float(emb_dim))\n",
    "    mat = posts/pows # rows = position in the sequence , # col = index along the embedding space\n",
    "    first_half = torch.sin(mat)\n",
    "    second_half = torch.cos(mat)\n",
    "    out = torch.cat((first_half, second_half), dim = 1)\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = positional_encoding(512,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "plt.imshow(mm.numpy(), aspect = 'auto')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4, 4, 3, 0],\n",
       "         [2, 3, 3, 2],\n",
       "         [3, 0, 4, 4]],\n",
       "\n",
       "        [[1, 4, 1, 2],\n",
       "         [0, 0, 3, 2],\n",
       "         [0, 0, 2, 4]],\n",
       "\n",
       "        [[4, 4, 4, 2],\n",
       "         [3, 4, 2, 0],\n",
       "         [3, 2, 1, 1]],\n",
       "\n",
       "        [[3, 4, 2, 4],\n",
       "         [4, 1, 1, 1],\n",
       "         [0, 1, 0, 2]],\n",
       "\n",
       "        [[0, 0, 2, 1],\n",
       "         [1, 0, 3, 1],\n",
       "         [1, 4, 4, 1]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 5\n",
    "seq_len = 3\n",
    "emb_dim = 4\n",
    "arr1 = torch.randint(low =0, high = 5, size = (bs, seq_len, emb_dim))\n",
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  1.0000,  1.0000],\n",
       "        [ 0.8415,  0.0998,  0.5403,  0.9950],\n",
       "        [ 0.9093,  0.1987, -0.4161,  0.9801]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2 = positional_encoding(emb_dim, seq_len)\n",
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.0000,  4.0000,  4.0000,  1.0000],\n",
       "         [ 2.8415,  3.0998,  3.5403,  2.9950],\n",
       "         [ 3.9093,  0.1987,  3.5839,  4.9801]],\n",
       "\n",
       "        [[ 1.0000,  4.0000,  2.0000,  3.0000],\n",
       "         [ 0.8415,  0.0998,  3.5403,  2.9950],\n",
       "         [ 0.9093,  0.1987,  1.5839,  4.9801]],\n",
       "\n",
       "        [[ 4.0000,  4.0000,  5.0000,  3.0000],\n",
       "         [ 3.8415,  4.0998,  2.5403,  0.9950],\n",
       "         [ 3.9093,  2.1987,  0.5839,  1.9801]],\n",
       "\n",
       "        [[ 3.0000,  4.0000,  3.0000,  5.0000],\n",
       "         [ 4.8415,  1.0998,  1.5403,  1.9950],\n",
       "         [ 0.9093,  1.1987, -0.4161,  2.9801]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  3.0000,  2.0000],\n",
       "         [ 1.8415,  0.0998,  3.5403,  1.9950],\n",
       "         [ 1.9093,  4.1987,  3.5839,  1.9801]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1+arr2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
