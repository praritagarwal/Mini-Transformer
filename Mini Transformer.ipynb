{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self attention\n",
    "class self_attention(nn.Module):\n",
    "    '''\n",
    "    Module to apply self attention to an input sequence of vectors\n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    emb_dim = dimension of the embedding vector\n",
    "    h = number of self attention heads\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, emb_dim, h):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.h = h\n",
    "        self.red_vec_size = emb_dim//h\n",
    "        \n",
    "        # Querry vector\n",
    "        self.WQ = nn.Linear(emb_dim, self.red_vec_size, bias = False)\n",
    "        self.WK = nn.Linear(emb_dim, self.red_vec_size, bias = False)\n",
    "        self.WV = nn.Linear(emb_dim, self.red_vec_size, bias = False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x has shape (batch_size, seq_len, emb_dim)\n",
    "        batch_size = x.shape[0]\n",
    "        seq_len = x.shape[1]\n",
    "        querries = self.WQ(x)\n",
    "        keys = self.WK(x)\n",
    "        values = self.WV(x)\n",
    "        att_scores = F.softmax(querries@keys.permute(0,2,1) \\\n",
    "                               /np.sqrt(self.red_vec_size), dim = 2)\n",
    "        ctx_vecs = att_scores @ values \n",
    "        assert ctx_vecs.shape == (batch_size, seq_len, self.red_vec_size ) \n",
    "        return querries, keys, values, att_scores, ctx_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "seq_len = 3\n",
    "emb_dim = 4\n",
    "h = 1\n",
    "x = torch.randn((batch_size, seq_len, emb_dim))\n",
    "attn = self_attention(emb_dim, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "self_attention(\n",
       "  (WQ): Linear(in_features=4, out_features=4, bias=False)\n",
       "  (WK): Linear(in_features=4, out_features=4, bias=False)\n",
       "  (WV): Linear(in_features=4, out_features=4, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "q , k, v, s, c = attn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3, 4]),\n",
       " torch.Size([5, 3, 4]),\n",
       " torch.Size([5, 3, 4]),\n",
       " torch.Size([5, 3, 3]),\n",
       " torch.Size([5, 3, 4]))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape, k.shape, v.shape, s.shape, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = q[0,0]\n",
    "keys = k[0]\n",
    "values = v[0]\n",
    "ctx_vecs = c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6311,  0.8655, -0.6542,  0.8358], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9810,  0.0888,  1.2204,  0.2591],\n",
       "        [-0.5531, -0.0441,  0.8234,  0.0949],\n",
       "        [ 0.2831,  0.3775, -0.8896,  0.3015]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1142, -0.1486,  0.9820], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1@keys.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2924, 0.2564, 0.4512], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrs = F.softmax(q1@keys.T/np.sqrt(4), dim = 0)\n",
    "scrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2924, 0.2564, 0.4512], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2924, 0.2564, 0.4512],\n",
       "         [0.3046, 0.2838, 0.4116],\n",
       "         [0.2343, 0.2961, 0.4696]],\n",
       "\n",
       "        [[0.4613, 0.2667, 0.2720],\n",
       "         [0.4006, 0.2337, 0.3658],\n",
       "         [0.3506, 0.3719, 0.2775]],\n",
       "\n",
       "        [[0.3710, 0.1780, 0.4511],\n",
       "         [0.3469, 0.2786, 0.3746],\n",
       "         [0.3605, 0.3517, 0.2878]],\n",
       "\n",
       "        [[0.5035, 0.3705, 0.1260],\n",
       "         [0.2137, 0.3649, 0.4215],\n",
       "         [0.4223, 0.2059, 0.3717]],\n",
       "\n",
       "        [[0.3654, 0.1255, 0.5091],\n",
       "         [0.3464, 0.3612, 0.2925],\n",
       "         [0.3637, 0.3061, 0.3302]]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(q@k.permute(0,2,1) /np.sqrt(4), dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0245,  0.2283,  0.1212, -0.0549], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrs@v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0245,  0.2283,  0.1212, -0.0549],\n",
       "        [-0.0014,  0.2885,  0.2080, -0.1357],\n",
       "        [ 0.0480,  0.1839,  0.0513,  0.0027]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0245,  0.2283,  0.1212, -0.0549],\n",
       "         [-0.0014,  0.2885,  0.2080, -0.1357],\n",
       "         [ 0.0480,  0.1839,  0.0513,  0.0027]],\n",
       "\n",
       "        [[ 0.3760, -0.3855, -0.8556,  0.4556],\n",
       "         [ 0.3390, -0.3638, -0.7825,  0.4329],\n",
       "         [ 0.3513, -0.3098, -0.7639,  0.3911]],\n",
       "\n",
       "        [[-0.0245,  0.0642,  0.0446,  0.1075],\n",
       "         [-0.0181,  0.1347,  0.0906,  0.0428],\n",
       "         [ 0.0565,  0.2402,  0.0605,  0.0106]],\n",
       "\n",
       "        [[-0.0197,  0.5554,  0.4535, -0.4049],\n",
       "         [ 0.0146,  0.2928,  0.2264, -0.3642],\n",
       "         [-0.1527,  0.4471,  0.5880, -0.5725]],\n",
       "\n",
       "        [[ 0.0635,  0.2675,  0.0897,  0.0344],\n",
       "         [ 0.0517,  0.4614,  0.2783, -0.2542],\n",
       "         [ 0.0629,  0.4318,  0.2335, -0.1895]]], grad_fn=<UnsafeViewBackward>)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn(x)[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_head_attn(nn.Module):\n",
    "    '''\n",
    "    Module to create multiple attention heads\n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    emb_dim = dimension of the embedding vectors\n",
    "    h = number of attention heads\n",
    "    parallelize = parallelize the computations for differnt heads \n",
    "    \n",
    "    '''\n",
    "    def __init__(self, emb_dim, h, p_drop = 0.1, parallelize = 'False'):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.h = h\n",
    "        self.red_vec_size = emb_dim // h \n",
    "        \n",
    "        self.heads = [self_attention(emb_dim, h) for i in range(h)]\n",
    "        \n",
    "        # transform the contatenated context vectors to have same size as emb_sim\n",
    "        # this is to be able to enable implement a skip-connection between the input and output\n",
    "        self.Wo = nn.Linear(self.red_vec_size*h, emb_dim, bias = False) \n",
    "        \n",
    "        # layer norm\n",
    "        # should we apply \n",
    "        self.LNorm = nn.LayerNorm(emb_dim)\n",
    "        \n",
    "        self.drop = nn.Dropout(p_drop)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ctx_vecs = torch.cat([head(x)[4] for head in self.heads], dim = 2)\n",
    "        transformed = self.drop(self.Wo(ctx_vecs))\n",
    "        \n",
    "        return self.LNorm(x + transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "seq_len = 3\n",
    "emb_dim = 6\n",
    "h = 2\n",
    "x = torch.randn((batch_size, seq_len, emb_dim))\n",
    "multihead = multi_head_attn(emb_dim, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = multihead(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 6])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0231, -1.9662,  0.3008, -0.1364, -0.1915,  0.9702],\n",
       "         [ 0.4701,  1.9460, -0.8554, -0.4478, -0.0873, -1.0257],\n",
       "         [ 1.0534, -1.7376, -0.5520,  1.0203, -0.3930,  0.6089]],\n",
       "\n",
       "        [[ 0.5825, -0.5098, -1.1385,  0.1325, -0.8846,  1.8178],\n",
       "         [-1.4548,  1.3502,  0.7119, -1.0193, -0.2577,  0.6696],\n",
       "         [-0.4788,  0.5429, -0.1157, -0.6507, -1.1968,  1.8992]],\n",
       "\n",
       "        [[ 1.2525, -1.1593, -1.4113,  1.0233,  0.0978,  0.1970],\n",
       "         [-0.3135, -0.4095, -1.3153, -0.4397,  1.8473,  0.6308],\n",
       "         [ 1.2602, -0.6129, -1.1350,  0.8786,  0.7792, -1.1700]],\n",
       "\n",
       "        [[ 1.3845, -0.5001,  0.3169,  1.0697, -1.0645, -1.2064],\n",
       "         [-0.1231, -1.0529,  1.7497,  0.0922, -1.2230,  0.5570],\n",
       "         [ 0.8774, -0.9101, -1.7569,  0.6996,  0.8852,  0.2048]],\n",
       "\n",
       "        [[-0.7497,  1.6234,  1.0140, -1.2375, -0.2001, -0.4502],\n",
       "         [-0.7554,  1.3924,  0.1645,  0.8395,  0.0197, -1.6608],\n",
       "         [-1.3110, -0.0224, -0.8433, -0.2656,  1.7294,  0.7128]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "multi_head_attn(\n",
       "  (Wo): Linear(in_features=6, out_features=6, bias=False)\n",
       "  (LNorm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0.], requires_grad=True)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(multihead.LNorm.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  9.3132e-09, -9.9341e-09],\n",
       "        [ 0.0000e+00, -9.9341e-09,  1.9868e-08],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.4835e-09, -1.9868e-08, -2.9802e-08],\n",
       "        [ 1.4901e-08, -5.9605e-08,  1.5895e-07]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx.mean(dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0954, 1.0954, 1.0954],\n",
       "        [1.0954, 1.0954, 1.0954],\n",
       "        [1.0954, 1.0954, 1.0954],\n",
       "        [1.0954, 1.0954, 1.0954],\n",
       "        [1.0954, 1.0954, 1.0954]], grad_fn=<StdBackward1>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx.std(dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder(nn.Module):\n",
    "    '''\n",
    "    The complete encoder module.\n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    emb_dim = dimension of the embedding vectors\n",
    "    h = number of attention heads\n",
    "    parallelize = parallelize the computations for differnt heads \n",
    "    ffn_l1_out_fts = number of out_features of 1st layer in feed forward NN. Default is 2048 a suggested in the original paper\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, emb_dim, h, parallelize = False, ffn_l1_out_fts = 2048 ):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.h = h\n",
    "        self.red_vec_size = emb_dim//h\n",
    "        \n",
    "        # multi_head_attention sub-layer\n",
    "        self.mul_h_attn = multi_head_attn(emb_dim, h, parallelize)\n",
    "        \n",
    "        # feedforward sublayers\n",
    "        self.l1 = nn.Linear(emb_dim, ffn_l1_out_fts)\n",
    "        self.l2 = nn.Linear(ffn_l1_out_fts, emb_dim)\n",
    "        \n",
    "        # layer norm\n",
    "        self.LNorm = nn.LayerNorm(emb_dim) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ctx_vecs = self.mul_h_attn(x)\n",
    "        out = torch.relu(self.l1(ctx_vecs))\n",
    "        out = self.l2(out)\n",
    "        \n",
    "        return self.LNorm(out + ctx_vecs)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "seq_len = 3\n",
    "emb_dim = 6\n",
    "h = 2\n",
    "x = torch.randn((batch_size, seq_len, emb_dim))\n",
    "enc = encoder(emb_dim, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encoder(\n",
       "  (mul_h_attn): multi_head_attn(\n",
       "    (Wo): Linear(in_features=6, out_features=6, bias=False)\n",
       "    (LNorm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (l1): Linear(in_features=6, out_features=2048, bias=True)\n",
       "  (l2): Linear(in_features=2048, out_features=6, bias=True)\n",
       "  (LNorm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-6.9687e-01,  1.1758e+00,  4.8854e-01, -1.6772e+00, -2.8876e-01,\n",
       "           9.9844e-01],\n",
       "         [-4.4651e-01, -1.0795e+00,  4.6523e-01,  1.5397e+00, -1.2227e+00,\n",
       "           7.4375e-01],\n",
       "         [ 1.3129e+00, -3.8853e-02, -1.8970e+00, -2.5361e-01,  7.7553e-01,\n",
       "           1.0110e-01]],\n",
       "\n",
       "        [[ 1.5190e+00,  5.5929e-01, -7.5171e-02, -1.7903e+00,  1.6400e-01,\n",
       "          -3.7685e-01],\n",
       "         [-6.8455e-01,  1.2850e+00, -1.3559e+00, -4.7717e-01,  1.3423e+00,\n",
       "          -1.0965e-01],\n",
       "         [ 9.2127e-01, -1.7478e+00,  3.3282e-01, -2.4043e-01, -5.4344e-01,\n",
       "           1.2776e+00]],\n",
       "\n",
       "        [[ 3.9487e-01,  4.0633e-01,  1.7275e+00, -8.3675e-01, -3.1522e-01,\n",
       "          -1.3767e+00],\n",
       "         [-1.6847e+00,  1.3860e+00, -1.9685e-01,  8.8583e-01,  2.1781e-01,\n",
       "          -6.0811e-01],\n",
       "         [ 2.1647e-01, -1.4033e+00,  4.6092e-01,  6.6572e-01,  1.3197e+00,\n",
       "          -1.2596e+00]],\n",
       "\n",
       "        [[ 1.0092e+00, -4.2293e-01, -9.3803e-01, -1.9140e-01,  1.6388e+00,\n",
       "          -1.0956e+00],\n",
       "         [-9.2380e-01,  6.6344e-01, -9.3539e-01,  9.6014e-01,  1.3182e+00,\n",
       "          -1.0826e+00],\n",
       "         [-8.7820e-01,  2.0061e+00, -9.2449e-01,  1.3934e-01,  1.9714e-01,\n",
       "          -5.3986e-01]],\n",
       "\n",
       "        [[-9.7832e-01,  7.4079e-01, -9.6843e-01,  5.9147e-01, -9.2109e-01,\n",
       "           1.5356e+00],\n",
       "         [ 8.8287e-01, -1.4218e+00, -7.2142e-01, -3.8916e-04, -3.4007e-01,\n",
       "           1.6009e+00],\n",
       "         [-1.4835e+00,  4.0010e-01,  1.4192e+00,  1.1412e-01, -1.0940e+00,\n",
       "           6.4408e-01]]], grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_out = enc(x)\n",
    "enc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 6])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 6])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder_decoder_attention(nn.Module):\n",
    "    '''\n",
    "    Module to implement the encoder_decoder attention layer. \n",
    "    This is same as the self_attention layer except that it takes two input vectors: \n",
    "                 1)encoder's final output \n",
    "                 2) output from previous decoder layer\n",
    "    The querries are generated from the previous decoder layer's output\n",
    "    The keys and the values are generated from the encoder's output \n",
    "         \n",
    "    '''\n",
    "    def __init__(self, emb_dim, h):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb_dim = emb_dim\n",
    "        self.h = h\n",
    "        self.red_vec_size = emb_dim//h\n",
    "        \n",
    "        # Querry vector\n",
    "        self.WQ = nn.Linear(emb_dim, self.red_vec_size, bias = False)\n",
    "        # Key vector\n",
    "        self.WK = nn.Linear(emb_dim, self.red_vec_size, bias = False)\n",
    "        # Value vector\n",
    "        self.WV = nn.Linear(emb_dim, self.red_vec_size, bias = False)\n",
    "        \n",
    "    def forward(self, enc_out, dec_out):\n",
    "        # x has shape (batch_size, seq_len, emb_dim)\n",
    "        batch_size = enc_out.shape[0]\n",
    "        seq_len = dec_out.shape[1] \n",
    "        querries = self.WQ(dec_out)\n",
    "        keys = self.WK(enc_out)\n",
    "        values = self.WV(enc_out)\n",
    "        att_scores = F.softmax((querries@keys.permute(0,2,1))\\\n",
    "                               /np.sqrt(self.red_vec_size), dim = 2)\n",
    "        ctx_vecs = att_scores @ values \n",
    "        assert ctx_vecs.shape == (batch_size, seq_len, self.red_vec_size ) \n",
    "        return querries, keys, values, att_scores, ctx_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encoder_decoder_attention(\n",
       "  (WQ): Linear(in_features=6, out_features=3, bias=False)\n",
       "  (WK): Linear(in_features=6, out_features=3, bias=False)\n",
       "  (WV): Linear(in_features=6, out_features=3, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "seq_len = 4\n",
    "emb_dim = 6\n",
    "h = 2\n",
    "enc_out = torch.randn((batch_size, seq_len, emb_dim))\n",
    "dec_out = torch.randn(batch_size, seq_len, emb_dim)\n",
    "enc_dec_attn = encoder_decoder_attention(emb_dim, h)\n",
    "enc_dec_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "q, k, v, s, c = enc_dec_attn(enc_out, dec_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4, 3]),\n",
       " torch.Size([5, 4, 3]),\n",
       " torch.Size([5, 4, 3]),\n",
       " torch.Size([5, 4, 4]),\n",
       " torch.Size([5, 4, 3]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape, k.shape, v.shape, s.shape, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1055, 1.0679, 0.7241], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = q[0,0]\n",
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = k[0]\n",
    "keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.2760, -0.6922, -0.5533, -0.9880], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1@keys.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.2760, -0.6922, -0.5533, -0.9880],\n",
       "         [ 0.0452, -0.1738, -0.6367,  1.0138],\n",
       "         [-0.2108, -0.0797, -0.5803,  0.6809],\n",
       "         [ 0.8407,  0.5261,  1.1788, -1.1274]],\n",
       "\n",
       "        [[-0.0912,  0.8676, -0.7004, -0.8413],\n",
       "         [-0.0349, -0.4209,  0.2272,  0.2838],\n",
       "         [-0.2665,  1.3260, -0.7065, -0.8829],\n",
       "         [-0.1835, -1.0982,  0.4689,  0.6033]],\n",
       "\n",
       "        [[-1.6119,  0.5404, -0.3440,  0.3651],\n",
       "         [-0.4196,  0.3210, -0.4347,  0.3786],\n",
       "         [ 0.1711, -0.1909,  0.4034, -0.3576],\n",
       "         [-0.4332,  0.1890,  0.4023, -0.3989]],\n",
       "\n",
       "        [[-0.1977, -0.1933,  0.1216, -0.4201],\n",
       "         [-0.1057, -0.7515, -0.7439,  0.2262],\n",
       "         [-0.0205, -0.6539, -1.1184,  0.0809],\n",
       "         [-0.3543, -0.2760,  1.5729,  0.3774]],\n",
       "\n",
       "        [[-0.2560, -0.2947, -0.5404, -0.0393],\n",
       "         [-0.3528, -0.3723,  1.6815, -0.4538],\n",
       "         [ 0.5769,  0.3728,  0.1997,  0.2831],\n",
       "         [ 0.1172,  0.3279,  0.6438, -0.0655]]], grad_fn=<UnsafeViewBackward>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q @ k.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.2760,  0.0452, -0.2108,  0.8407],\n",
       "         [-0.6922, -0.1738, -0.0797,  0.5261],\n",
       "         [-0.5533, -0.6367, -0.5803,  1.1788],\n",
       "         [-0.9880,  1.0138,  0.6809, -1.1274]],\n",
       "\n",
       "        [[-0.0912, -0.0349, -0.2665, -0.1835],\n",
       "         [ 0.8676, -0.4209,  1.3260, -1.0982],\n",
       "         [-0.7004,  0.2272, -0.7065,  0.4689],\n",
       "         [-0.8413,  0.2838, -0.8829,  0.6033]],\n",
       "\n",
       "        [[-1.6119, -0.4196,  0.1711, -0.4332],\n",
       "         [ 0.5404,  0.3210, -0.1909,  0.1890],\n",
       "         [-0.3440, -0.4347,  0.4034,  0.4023],\n",
       "         [ 0.3651,  0.3786, -0.3576, -0.3989]],\n",
       "\n",
       "        [[-0.1977, -0.1057, -0.0205, -0.3543],\n",
       "         [-0.1933, -0.7515, -0.6539, -0.2760],\n",
       "         [ 0.1216, -0.7439, -1.1184,  1.5729],\n",
       "         [-0.4201,  0.2262,  0.0809,  0.3774]],\n",
       "\n",
       "        [[-0.2560, -0.3528,  0.5769,  0.1172],\n",
       "         [-0.2947, -0.3723,  0.3728,  0.3279],\n",
       "         [-0.5404,  1.6815,  0.1997,  0.6438],\n",
       "         [-0.0393, -0.4538,  0.2831, -0.0655]]], grad_fn=<PermuteBackward>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(q @ k.permute(0,2,1)).permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1204, 0.3005, 0.3256, 0.2534], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1 = F.softmax((q1@keys.T/np.sqrt(3)), dim = 0)\n",
    "scores1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1204, 0.3005, 0.3256, 0.2534],\n",
       "        [0.2323, 0.2047, 0.1567, 0.4063],\n",
       "        [0.2193, 0.2366, 0.1772, 0.3670],\n",
       "        [0.2967, 0.2474, 0.3606, 0.0952]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4755,  0.7773,  2.0798],\n",
       "        [ 0.1360,  0.4734,  0.2271],\n",
       "        [ 0.0423, -0.0171,  1.2723],\n",
       "        [-0.2565,  0.5834,  1.0827]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0676,  0.3781,  1.0074], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1 @ v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0676,  0.3781,  1.0074],\n",
       "        [-0.1802,  0.5118,  1.1689],\n",
       "        [-0.1587,  0.4935,  1.1326],\n",
       "        [-0.1166,  0.3971,  1.2352]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5455, -1.0743,  0.2637], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2 = q[0,1]\n",
    "q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2323, 0.2047, 0.1567, 0.4063], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores2 = F.softmax((q2@keys.T/np.sqrt(3)), dim = 0)\n",
    "scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1802,  0.5118,  1.1689], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores2@v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3518,  0.0418,  0.4753], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq1 = q[1,0]\n",
    "keys = k[1]\n",
    "scores = F.softmax((qq1@keys.T/np.sqrt(3)), dim = 0)\n",
    "scores@v[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3518,  0.0418,  0.4753],\n",
       "        [-0.4657,  0.1529,  0.5513],\n",
       "        [-0.3086, -0.0077,  0.4688],\n",
       "        [-0.4950,  0.1789,  0.5791]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_head_enc_dec_attn(nn.Module):\n",
    "    def __init__(self, emb_dim, h):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.h = h\n",
    "        self.red_vec_size = emb_dim // h \n",
    "        \n",
    "        self.heads = [encoder_decoder_attention(emb_dim, h) for i in range(h)]\n",
    "        \n",
    "        # transform the contatenated context vectors to have same size as emb_sim\n",
    "        # this is to be able to enable implement a skip-connection between the input and output\n",
    "        self.Wo = nn.Linear(self.red_vec_size*h, emb_dim, bias = False) \n",
    "        \n",
    "        # layer norm\n",
    "        # should we apply \n",
    "        self.LNorm = nn.LayerNorm(emb_dim)\n",
    "        \n",
    "    def forward(self, enc_out, dec_out):\n",
    "        ctx_vecs = torch.cat([head(enc_out, dec_out)[4] for head in self.heads], dim = 2)\n",
    "        transformed = self.Wo(ctx_vecs)\n",
    "        \n",
    "        return self.LNorm(dec_out + transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "multi_head_enc_dec_attn(\n",
       "  (Wo): Linear(in_features=6, out_features=7, bias=False)\n",
       "  (LNorm): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "seq_len = 4\n",
    "emb_dim = 7\n",
    "h = 2\n",
    "enc_out = torch.randn((batch_size, seq_len, emb_dim))\n",
    "dec_out = torch.randn(batch_size, seq_len, emb_dim)\n",
    "enc_dec_attn = multi_head_enc_dec_attn(emb_dim, h)\n",
    "enc_dec_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = enc_dec_attn(enc_out, dec_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 7])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "multi_head_enc_dec_attn(\n",
       "  (Wo): Linear(in_features=6, out_features=7, bias=False)\n",
       "  (LNorm): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "enc_seq_len = 4\n",
    "dec_seq_len = 2\n",
    "emb_dim = 7\n",
    "h = 2\n",
    "enc_out = torch.randn((batch_size, enc_seq_len, emb_dim))\n",
    "dec_out = torch.randn(batch_size, dec_seq_len, emb_dim)\n",
    "enc_dec_attn = multi_head_enc_dec_attn(emb_dim, h)\n",
    "enc_dec_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5825,  0.2314, -0.0871,  1.1878, -0.7354,  1.4921, -0.5063],\n",
       "         [ 2.1371, -0.9590, -0.0456,  0.0407,  0.4044, -0.5633, -1.0142]],\n",
       "\n",
       "        [[-0.8367, -0.5809,  1.1473, -0.4594,  0.9021,  1.2566, -1.4290],\n",
       "         [-0.6285, -0.3225, -0.0123,  0.3943, -1.7571,  1.6886,  0.6375]],\n",
       "\n",
       "        [[-0.6189, -1.2911,  1.2547, -0.8207,  1.6273, -0.2217,  0.0704],\n",
       "         [-0.5710,  0.1586,  0.0643,  2.3108, -0.6349, -0.5634, -0.7644]],\n",
       "\n",
       "        [[ 1.3261, -0.4710,  0.2420,  0.1493,  0.0888, -2.0887,  0.7536],\n",
       "         [ 0.7919, -1.4163, -1.0918,  0.2870, -0.7728,  1.2891,  0.9129]],\n",
       "\n",
       "        [[-0.0049, -0.8477, -0.4687, -1.3792,  1.7102,  1.1053, -0.1150],\n",
       "         [ 0.0845,  1.8900, -0.6647, -0.9882,  1.0307, -0.5630, -0.7893]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_dec_attn(enc_out, dec_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4787,  0.1758,  0.0812,  1.3959, -0.9545,  1.2879, -0.5076],\n",
       "         [ 2.0926, -1.0435,  0.2474,  0.3530, -0.0164, -0.7385, -0.8946]],\n",
       "\n",
       "        [[-0.7540, -0.6133,  0.9736, -0.5767,  1.1325,  1.2379, -1.3999],\n",
       "         [-0.6942, -0.3792, -0.1381,  0.2258, -1.5779,  1.7958,  0.7678]],\n",
       "\n",
       "        [[-0.8495, -1.2767,  1.4893, -0.8838,  1.2699,  0.1748,  0.0759],\n",
       "         [-0.6369,  0.3687,  0.0556,  2.1963, -0.8476, -0.2022, -0.9339]],\n",
       "\n",
       "        [[ 1.6768, -0.1492,  0.3126, -0.3615, -0.1140, -1.9057,  0.5410],\n",
       "         [ 1.1211, -1.1274, -1.0408, -0.1686, -0.9393,  1.3565,  0.7985]],\n",
       "\n",
       "        [[ 0.1336, -1.2479, -0.5530, -1.1831,  1.5362,  1.1550,  0.1590],\n",
       "         [ 0.2815,  2.0475, -0.7514, -0.6693,  0.6693, -0.8974, -0.6802]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slfattn = multi_head_attn(emb_dim, h)\n",
    "slfattn(dec_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_out2 = torch.randn(batch_size, dec_seq_len+1, emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0689,  0.3102, -1.0180, -0.9410, -0.9588,  1.8263,  0.8501],\n",
       "         [-1.1982,  0.4798,  0.4758, -0.9345, -0.0737, -0.6874,  1.9382],\n",
       "         [ 0.0330,  0.3672,  1.9666, -0.3918,  0.0078, -0.3290, -1.6537]],\n",
       "\n",
       "        [[ 0.1886, -0.4317,  1.8125, -1.1055,  1.0329, -0.5438, -0.9529],\n",
       "         [ 0.9974,  1.1519, -1.2553, -1.2514,  0.9556, -0.7704,  0.1721],\n",
       "         [ 0.0976, -0.7475, -1.5488, -0.6047,  0.1723,  1.6123,  1.0188]],\n",
       "\n",
       "        [[ 1.8695, -1.4863, -0.1209, -0.3683, -0.7031,  0.0023,  0.8069],\n",
       "         [ 0.2162,  0.0424,  2.0732, -0.7594, -0.0695, -0.0651, -1.4378],\n",
       "         [-0.3043, -0.2585, -0.8746,  0.3061,  2.2664, -0.2505, -0.8847]],\n",
       "\n",
       "        [[ 0.7157, -1.9892,  0.5818, -0.1268, -0.7911,  0.4477,  1.1619],\n",
       "         [ 1.3221,  1.2725, -1.7518,  0.0332, -0.5668, -0.4657,  0.1566],\n",
       "         [-1.0578,  0.5653, -0.6794, -0.9340, -0.6460,  1.4846,  1.2674]],\n",
       "\n",
       "        [[ 0.7314, -0.5585,  0.9822, -0.5667, -1.3785, -0.7571,  1.5471],\n",
       "         [-0.1461, -1.9451,  0.0865,  1.2358,  0.2069,  1.1354, -0.5734],\n",
       "         [-0.2100,  0.9028,  1.7922,  0.1943, -0.9649, -0.3621, -1.3523]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slfattn(dec_out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder(nn.Module):\n",
    "    '''\n",
    "    The complete decoder module. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    emb_dim = dimension of the embedding vectors\n",
    "    h = number of attention heads\n",
    "    parallelize = parallelize the computations for differnt heads \n",
    "    ffn_l1_out_fts = number of out_features of 1st layer in feed forward NN. Default is 2048 a suggested in the original paper\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, emb_dim, h, parallelize = False, ffn_l1_out_fts = 2048):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb_dim = emb_dim\n",
    "        self.h = h\n",
    "        self.red_vec_size = emb_dim//h\n",
    "        \n",
    "        # multi_head_attention sub-layer\n",
    "        self.mul_h_attn = multi_head_attn(emb_dim, h, parallelize)\n",
    "        \n",
    "        # multi head encoder decoder attention sublayer\n",
    "        self.mul_h_enc_dec_attn = multi_head_enc_dec_attn(emb_dim, h)\n",
    "        \n",
    "        # feedforward sublayers\n",
    "        self.l1 = nn.Linear(emb_dim, ffn_l1_out_fts)\n",
    "        self.l2 = nn.Linear(ffn_l1_out_fts, emb_dim)\n",
    "        \n",
    "        # layer norm\n",
    "        self.LNorm = nn.LayerNorm(emb_dim) \n",
    "        \n",
    "    def forward(self, enc_vecs, dec_vecs):\n",
    "        dec_vecs = self.mul_h_attn(dec_vecs)\n",
    "        ff_in = self.mul_h_enc_dec_attn(enc_vecs, dec_vecs)\n",
    "        out = torch.relu(self.l1(ff_in))\n",
    "        out = self.l2(out)\n",
    "        \n",
    "        return self.LNorm(out + ff_in)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decoder(\n",
       "  (mul_h_attn): multi_head_attn(\n",
       "    (Wo): Linear(in_features=6, out_features=7, bias=False)\n",
       "    (LNorm): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (mul_h_enc_dec_attn): multi_head_enc_dec_attn(\n",
       "    (Wo): Linear(in_features=6, out_features=7, bias=False)\n",
       "    (LNorm): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (l1): Linear(in_features=7, out_features=2048, bias=True)\n",
       "  (l2): Linear(in_features=2048, out_features=7, bias=True)\n",
       "  (LNorm): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "enc_seq_len = 4\n",
    "dec_seq_len = 2\n",
    "emb_dim = 7\n",
    "h = 2\n",
    "enc_out = torch.randn((batch_size, enc_seq_len, emb_dim))\n",
    "dec_out = torch.randn(batch_size, dec_seq_len, emb_dim)\n",
    "dec = decoder(emb_dim, h)\n",
    "dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 7])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_ot = dec(enc_out, dec_out)\n",
    "dec_ot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 7])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(emb_dim, seq_len):\n",
    "    posts = torch.arange(seq_len).unsqueeze(1)\n",
    "    pows = 10000**(torch.arange(emb_dim//2)/float(emb_dim))\n",
    "    mat = posts/pows # rows = position in the sequence , # col = index along the embedding space\n",
    "    first_half = torch.sin(mat)\n",
    "    second_half = torch.cos(mat)\n",
    "    out = torch.cat((first_half, second_half), dim = 1)\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = positional_encoding(512,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzQAAAJDCAYAAADdIlG6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdfbAs+XnQ9+/Tv+455557933X2JZWL4ZFBRQJpjYy4D8wMZJlh7KoiinkVIKgTClQFoQEKmWTKjkliioTqgIBO8gLCAwVLBInkE3VJoqCcUECxlocYSMZRYvA2vW+Sbur3XvveZmZ7id/dM9Mnzkve/aeu6sZ7fdTNTX9e/9Nn+me0/N090RmIkmSJEnbqPpaT0CSJEmSbpUHNJIkSZK2lgc0kiRJkraWBzSSJEmStpYHNJIkSZK2lgc0kiRJkraWBzSSJEmSLiQiPh4Rz0fEvzyjPCLiL0XEExHxixHxW0dlH4yILwyPD96uOXlAI0mSJOmi/ibwvnPKvxt4aHh8CPgrABFxL/AjwLcB7wZ+JCLuuR0T8oBGkiRJ0oVk5j8CXjynyvuBv5W9nwPujohvAr4L+FRmvpiZLwGf4vwDowvzgEaSJEnS7fIW4MlR+qkh76z8S6tvRye3W7l2Net77/1aT0OStspvvufLX+spSNJW+bdPzvjKi218refxar7rd13NF15s35Cx/vkvHn0WOBxlPZKZj7yGLk5bn3lO/qVt5AFNfe+9fPOf/BNf62lI0lb5+d//sa/1FCRpq7z7u5589Uob4IUXW37+k297Q8Yq3/SFw8x8+BJdPAU8OEq/FXh6yP+OtfyfvcQ4S55yJkmSJOl2eRT4A8Pdzn4b8HJmPgN8EnhvRNwz3AzgvUPepW1khEaSJElSL4GO7ms9DQAi4qfoIy33R8RT9HcuawAy82PAY8D3AE8A+8AfGspejIg/A3x66OqjmXnezQUuzAMaSZIkSReSmd//KuUJ/OAZZR8HPn675+QBjSRJkrTRkjY3I0KzibyGRpIkSdLWMkIjSZIkbbD+Gprbcofjr0tGaCRJkiRtLSM0kiRJ0obblLucbaJLRWgi4n0R8fmIeCIifuiU8p2I+LtD+T+LiHdcZjxJkiRJGrvlCE1EFODHgffQ//LnpyPi0cz83KjaDwAvZeavi4gPAH8O+P2XmbAkSZL0ZpIkbXoNzVkuE6F5N/BEZn4xM6fAJ4D3r9V5P/CTw/JPA98ZEXGJMSVJkiRp6TLX0LwFeHKUfgr4trPqZOY8Il4G7gO+colxJUmSpDcV73J2tstEaE6LtKyv6YvU6StGfCgiHo+Ix9sbNy8xLUmSJElvFpc5oHkKeHCUfivw9Fl1IqIG7gJePK2zzHwkMx/OzIfLtauXmJYkSZKkN4vLnHL2aeChiHgn8KvAB4D/aK3Oo8AHgX8KfB/wM5le0SRJkiRdVAKtp5yd6ZYPaIZrYj4MfBIowMcz87MR8VHg8cx8FPjrwN+OiCfoIzMfuB2TliRJkiS45A9rZuZjwGNreR8ZLR8Cv+8yY0iSJElvdt4U4GyX+mFNSZIkSfpaulSERpIkSdLrK8Ef1jyHERpJkiRJW8sIjSRJkrThuq/1BDaYERpJkiRJW8sIjSRJkrTBkvR3aM5hhEaSJEnS1jJCI0mSJG2yhNYAzZk28oDmW+5+nr/xe/8yAF1WTCl02QeTWoI2K2YU2iGvo2Ka4zoVbQazrJfp7lg66LJaPgPMsu+vI/o6uWhThnnEsp/FvDqCNld99PWrY+mOGLWJ4bEKjC3Kx3VyaDdus5B5vP7ivb1Mj8uWfXIsnaOxxn3k2jjjuwOut+2XTytnlHlKG06Wn+hvbYMdtz8RbT2rj3PqnBqxfZV+z217bv4Z/VzERXZcF6gTr3UOt7LDvOxO9nbvpC+z3i8pvoYfOB/+1W+jrloACh111dFEn26ipUSfrqJb5ZE0MQegiqTQLdNlSC/qL+qW6CjDH62io8TqUtVCUkVHoTuWHpcv2w4ra9VXLscd5/dlK2X05z2Wv7Y+Shx/H6yfklA4+T6p4mTeafVWfZ5/osP6HG61n1dv//q/50t4UoekzbSRBzSSJEmSeol3OTuPX7dIkiRJ2lpGaCRJkqSNFrRvwKml28oIjSRJkqSt5QGNJEmSpK3lKWeSJEnSBktWd63VSUZoJEmSJG0tIzSSJEnShvOmAGczQiNJkiRpaxmhkSRJkjZYYoTmPEZoJEmSJG0tIzSSJEnShuvSCM1ZjNBIkiRJ2lpGaCRJkqQN5jU05zNCI0mSJGlrGaGRJEmSNlgStMYhzuSakSRJkrS1jNBIkiRJG867nJ3NCI0kSZKkrWWERpIkSdpg3uXsfEZoJEmSJG0tD2gkSZIkbS1POZMkSZI2WtCmcYizuGYkSZIkbS0jNJIkSdIGS6AzDnEm14wkSZKkrbWREZqGjnfUU6A/4mqiogy3qquoKBFUVFSj29eVeG3HZm12AHTk8NwN+at0S9IN6ZakG5W3MKQZWva305tltbytXpcx5JVleUtFN5wDOc1CRzXUqYfx+/SJOkN6luVYH4v+l+ms6IbzLBfj9vOolj/ItEjPu6GcoM3VmF3GmXnjPrpxObHMW5TnYpnjbXJUZ/ycHP/RqFyr39flWDpHYy76WC/vnzmWd7zO8brr9Vn2cXycY04ZZ73iuP2pnayVn+zrVdqfkXdi3LPantvvJW8Ved54FykfxEXncWLlXdAtNrsdQ5/f6cVe9+N/8Vvp6mG7aqCrIRfpepGGYdPvl+tk2P2QFWSddItPhpJknVDlMh11R5SkGvKq0lGGB0BdddSlo1SjdNXRlLbvIjompaWOlnpRJzp2ypw6+nRT9eVV9GM00faPqu+jIof0nMKqThUdZdgjN9FSoqMa0pNleS7nUdFRhjELuUwv6oz7W9YZla/y1tLj8qFs3Gb8aVXiZF5ff1zn+N//tE+7snY71ypOf8+s1zve7/mfo+e1fS39nN/2jbkt7Wv9n0HaBN62+Wxu0ZIkSZK21kZGaCRJkiT1Mr3L2XlcM5IkSZK2lhEaSZIkacN1XkNzJiM0kiRJkraWERpJkiRpgyXQGoc4k2tGkiRJ0tYyQiNJkiRtNO9ydh7XjCRJkqStZYRGkiRJ2mAJdBsUh4iI9wH/HVCAv5aZP7pW/heA3zUk94BvyMy7h7IW+KWh7EuZ+b2XnY8HNJIkSZIuJCIK8OPAe4CngE9HxKOZ+blFncz8z0f1/xjwraMuDjLzt9zOOW3OoZ4kSZKkTfdu4InM/GJmToFPAO8/p/73Az/1ek7ICI0kSZK04drcmB/WfAvw5Cj9FPBtp1WMiLcD7wR+ZpS9GxGPA3PgRzPz7192Qh7QSJIkSVq4fzjgWHgkMx8ZpU87ssoz+voA8NOZ2Y7y3paZT0fEtwA/ExG/lJn/+jIT9oBGkiRJ2mBJvJE/rPmVzHz4nPKngAdH6bcCT59R9wPAD44zMvPp4fmLEfGz9NfXXOqAxmtoJEmSJF3Up4GHIuKdETGhP2h5dL1SRLwLuAf4p6O8eyJiZ1i+H/h24HPrbV8rIzSSJEnShus25Ic1M3MeER8GPkl/2+aPZ+ZnI+KjwOOZuTi4+X7gE5k5Ph3tNwA/EREdfWDlR8d3R7tVHtBIkiRJurDMfAx4bC3vI2vp//qUdv8E+M23ez4e0EiSJEkbLOGNvIZm67hmJEmSJG0tIzSSJEnSBktik36HZuMYoZEkSZK0tYzQSJIkSRuuMw5xplteMxHxYET8w4j45Yj4bET8Z6fU+Y6IeDkiPjM8PnJaX5IkSZJ0Ky4ToZkDfzIzfyEi7gD+eUR86pR7Sf/jzPw9lxhHkiRJetPKhHZDfodmE93ymsnMZzLzF4bl68AvA2+5XROTJEmSpFdzW66hiYh3AN8K/LNTin97RPwL4GngT2XmZ2/HmJIkSdKbQ9DhXc7OcukDmoi4BvzPwJ/IzFfWin8BeHtm3oiI7wH+PvDQGf18CPgQQLnvbn7HP/5BACaTOTvNnN3JDIC9ZsbVZspePeWO+giAq/URe9WUa6VP75U+fbUayqsjdmPGbvR99MtzmujYjRaAJqABSvRvloagimAn+lVUIqhGAa2KoMRrC3C12QEdHe2QM+tTmXR0q3okXeZqGWiXaZgly9rtcBu/xZu8JZhlRUvQDaHJPq+mXdTJihllGbrsqPq8LEP9ijYXbYY6GbSs6nRrY8yy768bjdFlMMtCl7Hst8tVm24x91yN0Y1uSzjvCh0xtFltxOt9jMu7DHK0PtbzV+2DHP1t1suBUZplOtfmMe5jXNbXPVl2vM5p7cYdntKGk+Un23HMuP2J8rP6ODHO+MWcVue0Nheo96r5sVbtrIoX7O8W6sVrvU3mRcd+LW3inAqjorv+zs/DsF+KKqAUovTbbNQ1lAJ1TdR9HnUNdSGb4aOgqcm6IpthO28KWVd0zbC9NUHWhXZS0Q1NujqGxzCdGuZNMFuW93ldWZV3NWRJclGnQNZJlhzqZH/+QD3s6UoSJamG8qrqqEpHGR4AddVRl45S9emm6mhKSx19ulQdk6qlrtpV/ejYqeZDuqWJjio6mljVaaJdpstQVg19NtFSSJro+6giKXQ0MacMf7NC32cZ/lB9H/Nluhr25mUxT3Kov2pTjcrGz1WspUdvhjIasy9b5HPM+FOsHC9afh4u6669Dcsp/1xVcTLvtHqr8c//HF2fw3lera+xLttj6eoN+Efxtf7PIOniLrV1RURDfzDzP2Tm/7JenpmvZOaNYfkxoImI+0/rKzMfycyHM/PhcsfVy0xLkiRJ0pvELUdoIiKAvw78cmb+t2fU+UbguczMiHg3/QHUC7c6piRJkvRmk3hTgPNc5pSzbwf+E+CXIuIzQ96fBt4GkJkfA74P+KMRMQcOgA9knnliiyRJkiS9Jrd8QJOZ/zecf9JpZv4Y8GO3OoYkSZIkltc16yTXjCRJkqStdVtu2yxJkiTp9ZEcv+OrjjNCI0mSJGlrGaGRJEmSNpzX0JzNNSNJkiRpaxmhkSRJkjZYAp2/Q3Mm14wkSZKkrWWERpIkSdpoQXv+zz++qRmhkSRJkrS1jNBIkiRJG8xraM7nmpEkSZK0tYzQSJIkSRvOa2jOZoRGkiRJ0tYyQiNJkiRtsMzwGppzuGYkSZIkbS0PaCRJkiRtLU85kyRJkjZc6ylnZ3LNSJIkSdpaRmgkSZKkDZZA522bz2SERpIkSdLWMkIjSZIkbbTwGppzuGYkSZIkba2NjNDsPtvy6/78DIBut6bbnTDfLQBMr1Ts7wTtTjDf7eu3u0G7A+1On+52knYC3W4HQE46YqejmrQATCZzdpo5u5MZe00/ztVmyrX6iKv1tE/XR1wrR+xVfXpvWL5aHfXl1RG7MVs+AHZjThMdu9GP0wQ0QBP9OY+FoIqgoX8tJYKKiiqgGv4UJV7bMWab/WvsyGVeR0ebScdsVY8jusxhOemAdpmGWUK3rBu0GXQE7XC+5iwrWlY/6tQSzLJelrdZMaMsvz3oqJhmocuKdjhubnPRZqiTQUvFLMuQPj7GLPv+utG3El0Gsyx0OYxLRTf6saluMfdR/Y5g1q3adMTQZnUu6nof4/Iuo/9BK062yVGdLmP0VzhZDozSLNO53ueoj3FZX/dk2fE6p7Ubd3hKm7Wy09uxVrZ2Hu+ifJmfJ/s4Vv+M9ifyxi/4jHOHz2x7gbEvcDpyLjo7r8+Ljr0Ydv21vNo8zutz1DZ/+79DdTAHoDqaEYdTmPb7gZzNYDojDw/7ZSDbjmxbGPYj63+wACKCatgvRRVQClEKUQ8fH6VAXRN1vx1T19DU5CLd1GRdkc2wnTeFrCu6pqJrhvdjHbSTim7osqsrujro6kUb6Oogl+WQNXQF5kPetIask2F3QlcW6eG9WGf/FV49vNaSREmqobyqOqrSUYYHQF111KWjVH26qTqa0lJHny5Vx6Rqqat2VT86dqr5Mq+Jjio6mljVaaJdpstQVg19NtFSSJqYU0U/t0JHE3PKKF1FRxneGH0f82W6GvbmZVSnr3883feVx55XYy76Wr0nSuQyf1xWxu/fPP5NaeG4Esff7BXt8fL1jSGhipMbyIl6AENf1at8V7s+B1h9/q17tb7OU63NcfF5fTu91v8ZtL0Sjv0PouPcEiRJkiRtrY2M0EiSJElaaY1DnMk1I0mSJGlrGaGRJEmSNliuXcer44zQSJIkSdpaRmgkSZKkDdcZhziTa0aSJEnS1jJCI0mSJG2wzP73/HQ6IzSSJEmStpYHNJIkSZK2lqecSZIkSRvO2zafzQiNJEmSpK1lhEaSJEnaYP0PaxqHOItrRpIkSdLWMkIjSZIkbbgWr6E5ixEaSZIkSVvLCI0kSZK0wRLvcnYeIzSSJEmStpYRGkmSJGmjeZez87hmJEmSJG0tIzSSJEnShuu8y9mZjNBIkiRJ2loe0EiSJEkbLBPajDfkcRER8b6I+HxEPBERP3RK+R+MiC9HxGeGxx8elX0wIr4wPD54O9aPp5xJkiRJupCIKMCPA+8BngI+HRGPZubn1qr+3cz88Frbe4EfAR6mvxv1Px/avnSZOXlAI0mSJG24DbrL2buBJzLziwAR8Qng/cD6Ac1pvgv4VGa+OLT9FPA+4KcuM6GNWTOSJEmSNt5bgCdH6aeGvHX/YUT8YkT8dEQ8+BrbviYbGaHJoyn5L/4VANG1FKAsCiOIUqAUYjLpsyYN0TSwu9O3nzTkbkO32wDQ7dS0VwrzK339dmeX+U4w24UXd/pzBZ/fhXYHup3s60yg2026na4fd9JR7bTUTQvAzs6M3WbOXjNjr5kCsFdPuaM54mrp01frI/aqKXeUw768OmKvOmK3mvXl1RG7MRsecwCa6NiNloYc0jCJWB55NlFRCKohp0S/XI3ufNFEw0VuhNFmdyzdDWN2dEN5rpZp6TJpl3X68nbZFtqERY/TrOgIWmL5y7YtwSwLLYt01aeHbxw6qqFOPYy/Si/O6eyoaLNvt+ijG+oBzLL06WWfsRxjNY9+eZFetFncPaTN/l7v3XLMODVv3Ee3KGecXpXnqN24PEd1Fvk5Wj7Wdqi/qrsqG9cBln2sl/fL6+lY5q/nHcs/pc14rJN11t6GZ/R/opO1stW88tTy4xM4J2/Zdq3wou0Xw77a+cXnFS9fwhkTPGveoz7jnPGf+y+n7O/3+8H5/hViv1Dv99tCfTMoB1DvQ30w7F8Okvqgoz7ot9xy0FIO58RBv4+K6Yw4msK0T+dsBtMZOZ/THR31g7Yt2bbH30An5j/st4EqKqJU0DT9M0BdE3UN9fCRVBeyqaHu22RTlg+Arq7IpqJrKrp6eO83QVfHKl2v8hbprINuGKJPQzd8uGQNXZ3Mapgu8kr29UsOdRKqhLpPR+mIklRVn65KRxkeddUNL6WjVKt0U1rqqqOp+r1nXXXU0S7LJ1VLU7XUMaoTLU20VLH4XOjrNNGXVyRNNaewKq+io4mWMuyVS3RUdEwWbaKjkJTohj46ypC3nq6GOsu+FnVG9Rf5Vaylh/KyyE+OtVl8tpXl2zpPfNNaRm+tEqv3/4l6yw3l+GdbFce3mVmu1z9p8RnbLj/l1saKV9kPDLOobvF74+qCd7Na/xy/FSX8blsn3B8Rj4/Sj2TmI6P0aW/Q9Q+B/w34qcw8iog/Avwk8O9fsO1rtpEHNJIkSZJ6yfEvQF9nX8nMh88pfwp4cJR+K/D0uEJmvjBK/lXgz43afsda25+91YkueFguSZIk6aI+DTwUEe+MiAnwAeDRcYWI+KZR8nuBXx6WPwm8NyLuiYh7gPcOeZdihEaSJEnacJvyw5qZOY+ID9MfiBTg45n52Yj4KPB4Zj4K/PGI+F5gDrwI/MGh7YsR8WfoD4oAPrq4QcBleEAjSZIk6cIy8zHgsbW8j4yWfxj44TPafhz4+O2cjwc0kiRJ0gZLeCOvodk6XkMjSZIkaWsZoZEkSZI23Ab9sObGcc1IkiRJ2lpGaCRJkqRNlm/o79BsnUtHaCLi30bEL0XEZ9Z+VXRRHhHxlyLiiYj4xYj4rZcdU5IkSZLg9kVofldmfuWMsu8GHhoe3wb8leFZkiRJ0qtINud3aDbRG3ENzfuBv5W9nwPuXvv1UEmSJEm6JbcjQpPA/xkRCfxEZj6yVv4W4MlR+qkh75nbMLYkSZL0dc9raM52Ow5ovj0zn46IbwA+FRH/KjP/0aj8tLWf6xkR8SHgQwC77N2GaUmSJEn6enfpA5rMfHp4fj4i/h7wbmB8QPMU8OAo/Vbg6VP6eQR4BODO6r4TBzySJEnSm1FihOY8l7qGJiKuRsQdi2XgvcC/XKv2KPAHhrud/Tbg5cz0dDNJkiRJl3bZCM2vAf5eRCz6+juZ+X9ExB8ByMyPAY8B3wM8AewDf+iSY0qSJEkScMkDmsz8IvDvnpL/sdFyAj94mXEkSZKkNzNPOTvbG3HbZkmSJEl6XdyuH9aUJEmS9DpIwgjNOYzQSJIkSdpaRmgkSZKkDded+tOOAiM0kiRJkraYERpJkiRpk6V3OTuPERpJkiRJW8sIjSRJkrTBEiM059nIA5r5A3u89B+8G4DJjY7mektzYw5AuTklbh4SB0fk4SEAeTSlu3GTnPV16Npj/VURVFExafqXG3VNTCbEzgR2Jn0fk4bcmZBXGgDanUK7W2ivlH5Ou4V2p2a+G0N5cLgLN3eg3RmG3UnanaTb6fqMSUe101Kafj47O3N2mzlXmhkAe82Ua80Re/WUa/UUgKvliGvliL1y1Nepplytjtir+vRuzLhaHbEbfR9NtOzGjN3ox2hImoBJxDL81kRFIaiGnBL9cjW6uKxERVml+qdztps2+9fYkcNzN+Sv0i1Jl/1znwdtTln8dfo0Q0toCWZZ0Q4DdxlDXlnmtVR0WTHNMvRRDXXqYfw+3WX/WqdZ+jpZ0Q6vf5aFbjTOMj206QjarJgtxsgYxl3dMnGRng912uzHXJT3fazm0WXQjW65uOiry2p5kd8qb7Xic2g3Ls9RH4vnXKzTIW9cJ0f9dcmxdI7Gy1He+Llf5lib08pOrb821qgXRl0u6/XtxoOt3oar9nnsab2P9fkeL1srOFGPk058gOTp9S7Sx6t9Fp1VPl4lcfZr+H8e/hvsZ7+FfbWDF9tdnm/vAODL8zt5ZnY3zx7dxfNH1/q8g2t8df8KN/f7ndhsvyH2J5Sb/fu2PgjqfagP+v7r/aQ+SJqDjnLQb7n1YUt1MKc67PdJcTgjpjM46vdpOZvBfL7cP+d83j+Ojk75Q43XRRBlsS+qiFIt06WpoRSoa6IePsaamqwLDPv5LIVsCtn0ryWbQtdUdPWwbTQVWQftZEjXQVevngGyDrpmle5qyBq6siiHLLkqL9DWSRbIOod5JCweQJQk6o6q6tNV6SjDA6CuOqqqoykddbXKa0pLiT49KS11tKvy6KirliYW9fvl/nn4bIiWpmqphjdMn55TRukqOsqwR26iH6+io8SiTl9/MY++rFv2cSI96u943urvXkiqWG1ThVzOEViOvWyTufxsK6PtZfgrj/pltHx8w1q0n51XZ307W6vXnVJcnXLSS8vq/5ESF/tntKJafra+FtUtXjC++Dx/LUp4go82y0Ye0EiSJElaMUJzNg+xJUmSJG0tIzSSJEnSBkvCCM05jNBIkiRJ2lpGaCRJkqQNl0ZozmSERpIkSdLW8oBGkiRJ0tbylDNJkiRpw3W3+FtDbwZGaCRJkiRtLSM0kiRJ0gbL9Ic1z2OERpIkSdLWMkIjSZIkbThv23w2IzSSJEmStpYRGkmSJGmjhdfQnMMIjSRJkqStZYRGkiRJ2nBeQ3M2IzSSJEmStpYRGkmSJGmDJf4OzXmM0EiSJEnaWkZoJEmSpE2WkPm1nsTmMkIjSZIkaWsZoZEkSZI2XIfX0JzFCI0kSZKkreUBjSRJkqSt5SlnkiRJ0gZL/GHN8xihkSRJkrS1NjJCc98DL/M7/tinAfjSzXt45uadPHN9D4CjV/aort9J80pFc72vP7meTK4nzc0OgOZ6S31jSrk5BSD2D+HwiDw8AiCPjuhu3CS/+tWT98CL/ui3lEJd18RkMgzSEDs7MGn6PnYn5E5De6Wh2ykAtLuF+ZWKdqc/TpzvFtqdhvlu32e3Azd34JWdfsx2B7qdjpwk7LT9uDstTdOyO5kBsDuZsdfMuFL36WvNEVfLlKt1/1qulSOulSP2Sp/eq6ZcrY7YjRlXqz5vN2bDY96vn2hpomM3+nk0QImgGS42qyJoKJQIqtExb0VQok8vn5elw9Lalwdtdsvljhyeu6FsLU3SZdIO6W6o0w7LALOElqAdvqXoCFqCWVZDH0GXFe0wkVnWQ/2Kbngt0yx0VLRDm1kWWqpln32bavkDVi0VsyzH+u2ybz/LsppHHm8z7yraYcwu+3ktLuhrF+mMU/MWffbt4tQ+FmVdxvJbm0Wb5TofysZ9AORa+bGyDLrRZpGjOss2HC9f1TuZf7zOWeWLhVPaDOkgj5Wv93e887U34vp2fl4/J8oTTrtV5lm3zzztG7TT7rV53u031/s470u5Udn/dXA/31y/BMAD1RHvao741p1+69mJfeBZAI6y358c5pzrXcuLXf9R8GK7x/PtHTw3uxuAZ6Z38dzRnTx3eAcALx1e4eX9KxzcnNDd7PeF1X5NfbBLfbOfSH0A9X5SHzCkO+qDpD4Y9nGHLdXhjHI4h6NhH300g9mMnPXzyumQbvu5Z9uS89np63HYZxMVUQWUfpuMUohSqOrhY66uibrAMl3Ipoa6r59NIZtC1xSyHrbbpqJrgqyHbaQJujpomyFdB10NOXTZ1dDVFVn3y4u8LOM62ZcPu8x5SWZ1LnehWRJKQt0RpX+9VUmqqqMq/foopaOUjroa0lVSl5Zmme6YVO3yGaCuWuqqo47hc7JqqaOjWZRHSxPtss8mWkp0w+dFX6ca0mV48zYxp4qk0C3TZZSuoqOQlOiohrwy5J1ID/MqdMv+j/VxLG9ID1nVsFCGz7RF3eWnVyZlbRtalC0+w2bLPmLZ5lgfg9Muyq5isd9vj+WXtbrdcr7nf5fc0q7mcQGL/gWdiJQAACAASURBVLpzdyqntbv1b/vHn+3nWfyvoNsh/GHNc/hOkyRJkrS1NjJCI0mSJGnFH9Y8mxEaSZIkSVvLCI0kSZK04bzL2dmM0EiSJEnaWkZoJEmSpA2WaYTmPEZoJEmSJG0tIzSSJEnShvN3aM5mhEaSJEnS1vKARpIkSdpw/XU0r//jIiLifRHx+Yh4IiJ+6JTy/yIiPhcRvxgR/yAi3j4qayPiM8Pj0duxbjzlTJIkSdKFREQBfhx4D/AU8OmIeDQzPzeq9v8CD2fmfkT8UeC/AX7/UHaQmb/lds7JCI0kSZK04TLjDXlcwLuBJzLzi5k5BT4BvP/4XPMfZub+kPw54K23dWWs8YBGkiRJ0kW9BXhylH5qyDvLDwD/+yi9GxGPR8TPRcTvvR0T8pQzSZIkSQv3R8Tjo/QjmfnIKH1aGOfUq28i4j8GHgZ+5yj7bZn5dER8C/AzEfFLmfmvLzNhD2gkSZKkDZZc+HSw2+ErmfnwOeVPAQ+O0m8Fnl6vFBG/G/ivgN+ZmUeL/Mx8enj+YkT8LPCtwKUOaDzlTJIkSdJFfRp4KCLeGRET4APAsbuVRcS3Aj8BfG9mPj/Kvycidobl+4FvB8Y3E7glRmgkSZKkDXfBOyq/7jJzHhEfBj4JFODjmfnZiPgo8HhmPgr8eeAa8D9FBMCXMvN7gd8A/EREdPSBlR9duzvaLfGARpIkSdKFZeZjwGNreR8ZLf/uM9r9E+A33+75eEAjSZIkbbLkjbyGZut4DY0kSZKkrWWERpIkSdp0m3IRzQYyQiNJkiRpaxmhkSRJkjac19Cc7ZYjNBHxroj4zOjxSkT8ibU63xERL4/qfOSs/iRJkiTptbrlCE1mfh74LQARUYBfBf7eKVX/cWb+nlsdR5IkSXqzS6+hOdPtuobmO4F/nZm/cpv6kyRJkqRXdbuuofkA8FNnlP32iPgXwNPAn8rMz96mMSVJkqSve4nX0Jzn0gc0ETEBvhf44VOKfwF4e2beiIjvAf4+8NAZ/XwI+BDA295S8xe/6XEA2uw4yjkvd1MAvtzVPDu/gydn9/Fvjh4A4EsH9/CrN+/myzeuAnDjlStwfY/6lWsANK8EzQ2YXO9jdZMbHc31lubGnHKz7zduHhIHR+ThIQB5NCWnU7obN/sJdu36hCEqqqam1P1qnEwmxM4EdiZ9H5OG3JmQV5r+tezWtDsV7ZUCwHw3aHeC+W5Fu9v30e70j4OdfpibO8nzO0m30/UZk45qp6U0/Xx2dubsNnOuNDMA9pop15oj9uop1+r+tV0tR1wrR+yVo75ONeVqdcRe1ad3Y8bV6ojdmA3pOU107EZLM9wjsAmYRCxDek1UFIJqyCnRL1esNrYSFSVWQcCyvrS2XbbZQUA3jNnRDfm5WibpMmmXdZI2k8VfpwPaZKgNLcEsK1qCbtgR9HmFlkW6osuKaZahj2qoM/xNlu3X6mTFbEgv+lj0OcvSp7Ma6sex+l3G0GY8rz49X/SZ/ZiL8r6PPm/RRze8rmWdRRvG6VU59DvE9fJcq9NlLO8OucjP0Rh5rO6qbFwHVneYXC/vlxktL/rME/kn6q+9lrFFlTjWB5yslMfax7Gy0cIZ810vO56/VjE58V4n45S80XKc0seJcU6O/6f/1h/g6J7+3d/dM+Pa3Qd8453XAXjHtRd5+5UXeNvkK7yteRGAX1Nm3F3BtwyfBL+pmVPiZeBloN8mD3LKfvZb2Fc7eLHd5fn2Dr48vxOAZ2Z38+zRXTx/1O9vv3xwja/uX+Gl/X4nNttviP1CudnvF+uDoN6nfxzkkJc0Bx3loJ97fdhSHcypDvt9UnU4I6YzOOr3aTmbwXxOzubkfN5Pvm3JtoUhfeqZGRFEWex/KqJUMKSjqYlSqOqaGPbpNDVZF2j6dJZCNoVs+m0wm0LXVHT18L5vKrIO2kms8mro6qAbuswaumaV7uro88qqPEvS1ZDLvKQtMK+H921JWDyAKEnUHVXVp6vSUYZHXfXrtKo6mlG6rjqa0lKiT09KSx3tqjw66qqlGZ6B5XITi3RLU7VUy8+JlqaaU0bpKjoK3bJNiY6KjhKLOn39xTz6sm7Zx4l0dJTs6x7LI5d/9EJSjbahQlKNtsvF2GX0LqlGddfzVv3AbCgvsdr+qjPOA+rWNvIqFvv64/9PlBM7g36/2s/h/BNpSsTy8/E8p/XTXeAewNUpc3st2nz1uS2M/1+QXqvb8e75buAXMvO59YLMfCUzbwzLjwFNRNx/WieZ+UhmPpyZD99/n29qSZIkCRhCNPHGPLbQ7Thy+H7OON0sIr4xov9KIiLePYz3wm0YU5IkSZIud8pZROwB7wH+01HeHwHIzI8B3wf80YiYAwfABzK9R4MkSZKk2+NSBzSZuQ/ct5b3sdHyjwE/dpkxJEmSpDc7QwJn82IVSZIkSVvrdt22WZIkSdLrxQjNmYzQSJIkSdpaRmgkSZKkjRb+sOY5jNBIkiRJ2lpGaCRJkqRN5zU0ZzJCI0mSJGlrGaGRJEmSNlniNTTnMEIjSZIkaWsZoZEkSZI2ndfQnMkIjSRJkqStZYRGkiRJ2nheQ3MWIzSSJEmStpYRGkmSJGnTeQ3NmYzQSJIkSdpaHtBIkiRJ2lqeciZJkiRtOk85O5MRGkmSJElbywiNJEmStMkSSG/bfBYjNJIkSZK2lhEaSZIkacOl19CcyQiNJEmSpK21kRGaLxzezR9/+t8D4F17z/LQ5FkerOcAfHNpeVezz87eDHgWgFm23OiO+GrXAfBce4Vfnd/Dr0zvB+BLR/fypZv38MzNOwH48itXmV6fUL2yS3N9D4DmOkyuJ5Pr/eHv5HpHfbOlvjEFoNycEvuHcHAIQB5NyaMjcjan29/vJ37z5vEXEkGUQtT9am4mE5pJQ+zs9OWThtydkDsN7ZUGgG63MN8ttLv9sWa7E8x3g3anADDfrel2oB26mO4kBzvwwk7/2nOSsNNSdlqapgVgdzJjdzJjr5kBcLWZsldPuVr613a1PuJa6R8Ae+WIvWrK1eqIq1Wftxuz5aNPz2miYzf6PpqABijRn9/ZEFQRNJRlXjUcP1f06RLHj6cX6bLKGdYjtNktc7tYfUXR0dFm0rEqb0m64WuMllzWaZdtYJbQDvNoM+iIZXqWFS1Bl8PfgGCWNS1BO+TNKLRZ0Q2vqc2KWRbaZXrRpk93GbT0dfr0aoxFXt/faoxFm3m3mEdFl6t59XX7dDecVzvOW/TREavyjBN9rPL6OrnWZtEu1/pYyLXycf1u9G1SnlaH4+XHn4/nr5bznPLFwnqb1VzH5bHW1/FKfSKXddfKz/im7MQ3aONznhdlsVYpxwOc0i5G9ZZ5eSLvHX/5s8QddwDQ3XWN+X1XOLy3T3/mnrfyc/cG03uS6T391lDfPeW+u2/wzddeBuCdV1/gHbsv8ODkBQC+uX6JB6o5d1f9++XtdcOvbwqwPzzgKJ9kv5txfdhGv9rVvNju8Xzbj/vc7G6emd7Fc0f9/ve5wzt44WCPV/Z3eWV/0s/1ZkO1X1Hv99tCvT+hPoB6v39x9QHUBx31wSLdUg7mVEdzqoN+n8R0RhzNyOl0mc75HGZ9ebYd2bZkO+wJck7O1tZ5BERFVMMKL4UoBUo/r6jr4THsm+oa6kI2w0dpXcimf3RNXyfriq6p6JrhfV0HXRN09bD/GZa7oYusoavp8xpWbQoMu4qhTpJDm74saethv1dgWhJKQt3/XaIkVUmqqk9XpaMMD4C66qhLRxnKm6pfnlTtMm9StdRVSz2k6+hoqpY6Fm1a6mhpol322URLiW6Z10RLNUoXkibmVMP7udDRxJwySlfRUYY3eomOio4yyjuRjo6Sq/Qyb9FHLurl8TrkcnsqJ8pgBpThrTFb9MFK4bhubZuu1nYOhcV+ezzP441a2mW9U+Wrfy9dIo59Rp6lOuU77u6Ct9WqzpvjBY0/59et/7/wpmWE5ky+QyRJkiRtrY2M0EiSJEka8S5nZzJCI0mSJGlrGaGRJEmSNtz65ZdaMUIjSZIkaWsZoZEkSZI2WeJdzs5hhEaSJEnS1jJCI0mSJG208C5n5zBCI0mSJGlreUAjSZIkaWt5ypkkSZK06bwpwJmM0EiSJEnaWkZoJEmSpE1nhOZMRmgkSZIkbS0jNJIkSdKmM0JzJiM0kiRJkraWERpJkiRpkyX+sOY5jNBIkiRJ2lpGaCRJkqQNF15DcyYjNJIkSZK2lhEaSZIkadMZoTmTERpJkiRJW8sDGkmSJEkXFhHvi4jPR8QTEfFDp5TvRMTfHcr/WUS8Y1T2w0P+5yPiu27HfDygkSRJknQhEVGAHwe+G/iNwPdHxG9cq/YDwEuZ+euAvwD8uaHtbwQ+APwm4H3Afz/0dyke0EiSJEkbLvKNeVzAu4EnMvOLmTkFPgG8f63O+4GfHJZ/GvjOiIgh/xOZeZSZ/wZ4YujvUjygkSRJknRRbwGeHKWfGvJOrZOZc+Bl4L4Ltn3NNvIuZ/lcw8/95YcB+IcPBIf3J/MHZgDccd9N3nHPS7zrjud46MpzAPzayXM8WB/yQNUfn721ht+2+wrwCgBH+Xn2uxkvdh0Az7Z7PDm7j1+Z3s+Th/cC8KX9e3j2xh288MoeALPrE8orDc31HQCa6zC5nkyu94euzY2O5sac+saUsj8FIPYPyYNDODrqX8d0Rk6ndEOaw8PjL7QqRClEU1NPmj6vmbCzM4EhnbsTup2G7kr/p2p3a9rdina3f63znWC+G7Q71VAefZ0JtLv9XK9Pkpd3kpz0rz92OsqkpZnMAdidzLgymbHX9Ov4Sj3jWn3E1XrK1bqf+7VyxF415Y7Sv4a96ojdasbVqi/fjdny0afn7ETLJKY0ww/bNkATQaHPaKKioqJEn+5Tq1/BLVGdvnxsJRYIaLNb5nQki246OtpMuliVtyRdJu1wu5COpM2O2aI8oQPaoZM2g45gltUqj6DLiukwm24oa7Of54xCmxXd8J3BNMtQp1r2Ocualopu+OXfPt33Ox5jlmVoU9GNxugymGWhy1j222XfphvPPcdjVMfSHTG0iVXeon9i1OeqPIf1sao/yh/ljb/k6TKOla/qcyydo/L1PnI0Tv98PP94WZ7IG7dhrc3wFlyNNyoPkjw2keMLy/6H/EVfyz5iUQ9Gb++1Out9c/xrssVicPKXokfJuHaN7qsv902eeZZqPmdvKLu6s0O1t0fceY3u7msAzO69wuG99/Glex8A4P+79yGm9ySzu1sAmrsPeeDuGzx4x1cBePvei7xz58s8OHmBbyz9/vWBMuWuqvBN1RUA3lYXoKPNlwCY8xX2uxnXh230xbbhhW6PZ+d389zsLgCemd7Fc0d38JXDfl4vHuzxyv4u1/cn/WvZryk3K8p+/96s92vq/R3qg6TZ71dOfZjU+x3lsB+nHMypDudUR/2WXR1OYTojZ8OWPp2R8zkM6Ww7sm0hO3I+rPD5/PhNhSIgKqIMe6Eq+n14PXyUDstVXSiLvKYm6wJNn86mkHVF1/R99MsV3WTY7uqga4Ku7pdXedANXXZ1kHUs01lDV4JclkPWSVdg2H0M6aSth1dUAXUHpU9HSaqSVKUdXkpSSkdVddRVv07r0tGUljK8N5vSUkefB1BHR121y/qTak4z5DXDPriuWgqrPptoaaKlxCpdRUcTwzxImphTDWMWOpqYUyIpdMOfoVvWAyhDuhrKS3SQfV+r+h0lk2r02VDIZR0SqhilgYrj6WV/Q3oGlNH2OMs89q3x+jk13ajuol6bi9c52heO5xDHt/+W9ljdsWr5eXP6V+5lra+O7tR6477O0p1z+63qjPm9FuPP+NOM/0f4ura+/3/93B8Rj4/Sj2TmI6P0aRNZfxOcVecibV+zjTygkSRJkvQ18ZXMfPic8qeAB0fptwJPn1HnqYiogbuAFy/Y9jV7kxzSSpIkSboNPg08FBHvjIgJ/UX+j67VeRT44LD8fcDPZH/6xKPAB4a7oL0TeAj4+ctOyAiNJEmStMmSjflhzcycR8SHgU/Sn0358cz8bER8FHg8Mx8F/jrwtyPiCfrIzAeGtp+NiP8R+BwwB34wM9vLzskDGkmSJEkXlpmPAY+t5X1ktHwI/L4z2v5Z4M/ezvl4QCNJkiRtug2J0Gwir6GRJEmStLWM0EiSJEkb7oI/evmmZIRGkiRJ0tYyQiNJkiRtOiM0Z7pQhCYiPh4Rz0fEvxzl3RsRn4qILwzP95zR9oNDnS9ExAdPqyNJkiRJt+Kip5z9TeB9a3k/BPyDzHwI+AdD+piIuBf4EeDbgHcDP3LWgY8kSZKkM+Qb9NhCFzqgycx/RP+jOGPvB35yWP5J4Pee0vS7gE9l5ouZ+RLwKU4eGEmSJEnSLbnMNTS/JjOfAcjMZyLiG06p8xbgyVH6qSFPkiRJ0gVEepez87zedzmLU/JO/XNExIci4vGIeHw2vfk6T0uSJEnS14PLHNA8FxHfBDA8P39KnaeAB0fptwJPn9ZZZj6SmQ9n5sPN5OolpiVJkiR9ncl4Yx5b6DIHNI8Ci7uWfRD4X0+p80ngvRFxz3AzgPcOeZIkSZJ0aRe9bfNPAf8UeFdEPBURPwD8KPCeiPgC8J4hTUQ8HBF/DSAzXwT+DPDp4fHRIU+SJEnSRXmXszNd6KYAmfn9ZxR95yl1Hwf+8Cj9ceDjtzQ7SZIkSTrH631TAEmSJEl63Vzmts2SJEmS3gDetvlsRmgkSZIkbS0jNJIkSdKmM0JzJiM0kiRJkraWERpJkiRpk6XX0JzHCI0kSZKkrWWERpIkSdp0RmjOtJEHNPHyPvf87Z8H4L6re1R33Ul3350ATO/f48vfcBdfeuBbePSBHPJadu474C33vgzAu+56nl+/9ywP7TwLwIP1Id9YkrfWOwD82qaC3ZeY5VfYzykAL3ctz7Y7PDu/C4BfmT7Al47u5Vf27wXg6Rt38eKNPV54ZReA6pWa+voOk+u7NNf7eUyuJ5MbHc31FoD65ozqxpSyf9i/sINDcjolD48AyOmMbFtyNoX98QoIopR+sa6JpqHemQDQNA3s7pCTpu9jt6G70tDu9n/KdrfQ7gbznYr5bvR5O0G7W9HulCEN7U4y61cHhzvJSzsdTDoAyk5L3czZmcy5MpkBcKWZcbWZslf36+uO+oir9RFXSl9+Rzlkr5qyV/Wvba864mo1ZbeacjX6Nrsxo4mW3ejXTxMtDXOafppMImgIqugzSgZN9HOuhmBiRVDiZGBxnFeOl9DSv65utCfooqPNtfRQ3mXSkkMraLOjBTpa2qHJjKDNoGNYxwRdBtNhnl1WtATtkJ5loc2KbkhPs9BR0Q71+jr10OeiTk2Xqz66rPp+hvpd9u1nWVbzyGqtTfTluWrTDXNfpofXcVreoo/FY9zHKt0v56jNOB/oy0Zp6PfL4/JFm8xxH6uycZ1xH+P6q7rjdK7VWbTsy4Nc1g+AjGVcf9lu1XzoZJSxHGytylr6xKkCo3GW9WOtfNl41P+4o7U+/9WffJArz/V/+yvPJVefm7P7/AEA5YXr5FdfoX36OfJXnuzzgGt1zZ17e33Xd1wj77rG/J4+fXTvLgf3XuWX7/1GAD5zTzK9pyPumXL3XTcBeMudr/COqy/wjt0XAHj75Cu8pX6JB0o/7l1VcEc14c5hy3xbXQEts3ye/XwKgOtdy8td4YXuCgBfnt/Js/O7eGZ6NwDPHd3Jlw+v8ZWDqwC8fLDLzf0d2ps11X7fb9mvqPcL9bAvrQ8m1PvQHOSQ7igHLfVBv/+pjuZUBzOY9vuwajqDoyk5m8Fs3q/e+Zyczcm2HdZ3B11Ldu3xP0Es3icVUQWUstyHUwpR11CGfVhdQ11Tmn6fnXWBpibrvjz/f/buPUay9Lzv+/d533Oqqm/T0z09e+POzO6S1CorydpAG5mXxDEp0VkTgkUFsizGiChECv2PgCS2BFFQgAiCDchwDCWAjRhriRYdC7ISG4QYkRZFMnIE2xStXYkUb0vuanmbS3fPdbt7qrou533yx3uqurqnq6e5M5yt4v4+wEGd93Le9z1Vdd4zZ55Tp8uIl5FUBLysj+MykAojNepjoLB6YS9dsi/tdfkwz6PhBaSi/m5H8Bj3pVPhVDGn+9EhOhYToa4TQiLERIz1uSImojlFnS5iRTSnjPU5MCTKUFGERCMMRnmF5XxgtF6MnReKkIj1DFyGitIqQv1lL8OAiOc8S6NtIol4ID0sjzjREqFuM1oi4oSxbSJOsL1+Iw7O/jbqPIBgdRpGYxttd2B9eHbqA3HssB6egyKw942CaLbvfDV+xqvciQcmpISPzpscKJkkEPadAw8Tx9pMR7Q1bG+SdMS/wsMtk+srU/nk8R32bwb59jOVFzQiIiIiIjJGEZqJdNkqIiIiIiIzSxEaEREREZEpp6ecTaYIjYiIiIiIzCxd0IiIiIiIyMzSBY2IiIiIiMws/YZGRERERGTa6Tc0EylCIyIiIiIiM0sXNCIiIiIiMrN0y5mIiIiIyDRzPbb5KIrQiIiIiIjIzFKERkRERERk2ilCM5EiNCIiIiIiMrMUoRERERERmXaK0EykCI2IiIiIiMwsRWhERERERKaYoaecHUURGhERERERmVmK0IiIiIiITDtFaCZShEZERERERGaWIjQiIiIiItPM9RuaoyhCIyIiIiIiM0sRGhERERGRaacIzUSK0IiIiIiIyMxShEZEREREZNopQjORIjQiIiIiIjKzdEEjIiIiIiIzaypvOfPleez13wlAuHyDdP0G6cJFAAp3louClfl5bGUZgGr1BN375rh5+iEA/v3ph/n4aae/NgBgYa3Nwydv8B0nNgF4fH6dNzbWOVO0OR1z/O7+2ORsUUKzDUB//iV20he5kRIAG9UcFwYrfK23BsBXd09xvn2SSzdPcG1rAYDr2w3CVkG5nd/WcrtJY9tpbOc+GtuJcmdAvNkHIN7sYe1d6Ozi3V7e924X7w/wQa7jgwHs7sJ2/eaYYUWJxXwtao0GsVFSNJu5vFHirQbeLKnmSgBSKzJoRapW3qZqGoOWUdWbDFqBqhVIjZyuWs6gAb1mYqtRxzebFbFZUZYVAK1Gn1ajz3yZx7lQ9pgveizEvB8LRZfFmJf52AVgPvRYCF0WQk63rD9acnpAaYmW5T5Kg5IB0YwSy98HM0qPRKvT9TV5qMuj3XqNPsyL+3OpSKNUGovjJktU7qRhuUGFk9yp6mcmJqDyRDXaHvoOVT2Oyo2EjdJ9D1QYyevPAKPvBRVGVef1iVQeSPU+VR7oe6QapYfb5HRyoyLXGW831dsN20hjfQy3GaRh/UDyvE0aH7vn/LxvNsobtpGwvXK3W9rYy8tpP7DNsI4faAP2Iurj5ePpNBZy98PqsL98/+v+fPB92+fyvTzDcSfv1Xi9sT4YNWXs4+MDHas37N/2l5sdaMN8XxOH9mP7B/Ov3/W/8+nuGQD+ZOccn776MC9snsxV1x9ibuN1zG8485v5mGtudojXtvCXtwCoNjbxCxdHXc2VDRYW5rClJQDS8iKDU3PsrjbYXWkB8JXVNb608ii9lXw0FCd7nDq5w8NLNwA4N3+NR1pXOdO4CsBDxXVOhy4nQ2A+5DlquZjj4bFd7fpV2mmdbc/H4I1UcK2aZ32Q5/z1wTKbvRNsdE+wsZvHdrUzz1a7xc12nsjSzZLQDhTtvDdFu6DoFBTt/IYVHSg6ibKd+4i7idgZELoDQie/P9brE7p9vJfnNXr9PCf36/m5SnhVQT1OUpVXB4O9j8UMLGChfldjxGKEmI9RKwooCkJRz1BFAUXEy/wK4GXEy0gq63QRSGUglfX3ujBSaVR1OhVWL+D1WT4Vdf5oG0gxbwvgEVLhe/UjeHS8cFI9tCo6RIci769FJ0QnhJwOMRHrBaAIiSImYkiUdZ0YEo1QEet0I1QUoaKo04UlylBRWE7n9YqyPi8UIVFaRbQ0yiutIoylI05pA0J9jEUSpQ2IY+lgiYgT634CiVjn7UvXB2Guv7982FccOwjDWLpfp4ei5fPIXt36vT4wdVRjdSKMzjO5Ddt3vgpj20T2NzSsF+xAB3XpYcLY/3NX+yag/aId7Ov27R0mHXEPVeCwcX/zKj98bIf9e2Ha6bHNk83epykiIiIiIlKbygiNiIiIiIiMUYRmIkVoRERERERkZilCIyIiIiIyzRxFaI6gCI2IiIiIiMwsRWhERERERKacnnI2mSI0IiIiIiIysxShERERERGZdorQTKQIjYiIiIiIzCxd0IiIiIiITDnze7Pc0RjNVs3sY2b2Qv26ckidJ83sk2b2eTP7MzP7G2Nlv2FmXzGzT9fLk8fpVxc0IiIiIiJyN7wP+IS7vxH4RJ0+qA38hLt/F/A08L+Z2cmx8p9z9yfr5dPH6VQXNCIiIiIi087v0XJnfhj4QL3+AeBdt+yG+5fd/YV6/SKwCZy+k051QSMiIiIiInfD/e5+CaB+ve+oymb2/UAD+POx7L9X34r2q2bWPE6nesqZiIiIiMg0uzvRk+NaM7Nnx9LPuPszw4SZfRx44JDtfvGb6cTMHgT+T+A97p7q7F8A1skXOc8APw/88u3a0gWNiIiIiIgMXXH3pyYVuvsPTiozsw0ze9DdL9UXLJsT6p0APgz8z+7+R2NtX6pXu2b2z4CfPc6AdcuZiIiIiIjcDR8C3lOvvwf4nYMVzKwBfBD45+7+fx8oe7B+NfLvbz53nE51QSMiIiIiMsXsHi536FeAd5jZC8A76jRm9pSZ/Vpd58eAvwT85CGPZ/5NM/ss8FlgDfi7x+lUt5yJiIiIiMgdc/erwA8ckv8s8NP1+r8A/sWE7d/+SvrVBY2IiIiIyLS7dw8FmDm65UxERERERGaWIjQiIiIiIlPOFKGZSBEaERERERGZWYrQiIiIiIhMO0VoJrpthMbM3m9mm2b2PH0GMwAAIABJREFUubG8f2Bmz5vZn5nZB83s5IRtv2pmn60fx/bsYXVEREREREReqePccvYbwNMH8j4GfLe7/wXgy8AvHLH929z9yaP+4qiIiIiIiBzB79Eyg257QePufwhcO5D3++4+qJN/BDz8LRibiIiIiIjIke7GQwH+O+DfTChz4PfN7Dkze+9d6EtERERE5LXF81PO7sUyi+7ooQBm9ovAAPjNCVXe6u4Xzew+4GNm9nwd8TmsrfcC7wVo3b/En/9cCYBfOMvCxXMsXEwALFzsUm5swdXrVBc3cp2vfYOGGa1mE4DV5ROwukx/bRGAzn2LbJ4+wdfXzgHwu6cTYa3L/ade5vXLVwD4joVNvqN1iUfKnH4gdlkNBWeLFgCPloHKb9Cdz+Uvpx6XU8H6YIlv9E8B8JXuab7eWeHCzfyToss7C1zfmoPtvC/FVqTcKmhs5zbLHaexnSh3KsqdHPCKN3uEm7tYp5v3bXcX7/bwXi+n+wO838P79Ru3uwtmYPna1MoCKwqs0aBsNnKdZoNGs4G36ve0WVK1Cqq5CEDVDAxaRtU0gLzeMqpmpMpvKVWzoGo6vWb+pu82EzQSoVnlfWtUNBoDWmXej7myz3zZY7HsMl/ksS8WPRZil8WY920+dpkPPRZCnQ5dWtYfpVvWp2UDSku0LPdTkiitomF5rAEoLRCp0x6IZoT6Wj3U+dFuvXYfz4v7S6hIo1TCSSQwqNzrvERlTqrTFU4aK6/MSUBVTwzJoMLoe6jrG8n7dV4c5VUEUl2n55FEoKr3oe8Fle+lk4e9OvU2fY/72hi2P0p7IGFUYa9+8mG/w3ZzepBiva9G5TZqI7mN8objGOaNt5HGt8FGecNyAB+mx8r9QJ1R3bH14bbj9XNd9qWHdYYztI/69LH+HR+bwN3tQHr/68GEjY1vHxtbH+1vXTQ8Y/heXR8b57DMDmljtC9j2w7L12Kfv7l0CYCfPLFJ98H/wMVBPp6+1D/Fs+1H+ZMbZ/jylfsAuLm+QGt9mfmN3Nj8ZmJuY5fiyk5u8/oWvr1N9fJWTn/DCSGy2GqytJTnV04sUq0s0D2V57XuSovd1Xm+sJL7+NOVRFrps3iyA8BDJ7Y4u3idc3NXOdvI8+nZ8hr3xx1OhnzcLYcGJ0KLlfoYPQtUPqDjed/afp4bCa5VLTarJQAuD05wqX+S9e4yAJvdRS53FrnRnsv72m7SbpdYO3+v481A0YkUdbpoQ9FpUHScspPHETuJYrcidPK8Fnb72G4f69UTcLeH9/swyOXe6+NVBVWVX4cflFf4cEoZDPLHXn+4FiNYwGI9H8WIlQXECEU+RYeigLIgFPVMVRZ4jHiZ014GvIyksj7eCiOVAS+MqmF7eYWTimEaUgk+ni4Mr/9VkGIuS4VTT1F4BC8cj3W/hVPFvOSxOxYdK/LOhuCEmIj1AlCERAiJcixdhEQZ8/sVLdGIFUU95xchUViiCDndDBVlqAj4KK+0Ki91OuB1uj6v1ulg9edan0eiJUI910dzShsQ64MyWiJ4Ig63cSdwIG2JOHauiNR1xmaDiBPqY7bvwzpj5eaj/KHxs1Wy/XnDc8zwnFUB0YbzqN+y/XCbuG9CgoPJsR4nFYzOq+PjGBft1kbTIe2FY/5fejrk3qcweeDftKo+KH1W77GSfV5xhMbM3gP8EPA33Q/5ZgPufrF+3QQ+CHz/pPbc/Rl3f8rdn2osz73SYYmIiIiIfPvRb2gmekUXNGb2NPDzwF9z9/aEOgtmtjRcB/4K8LnD6oqIiIiIiLwSx3ls828BnwQeN7PzZvZTwD8Clsi3kX3azP5JXfchM/tIven9wL8zs88A/xH4sLv/3rdkL0REREREvo3pNzST3fY3NO7+7kOyf31C3YvAO+v1l4DvvaPRiYiIiIiIHOFuPOVMRERERETkVXFHTzkTEREREZF7YEZvB7sXFKEREREREZGZpQiNiIiIiMiUm9Uf7N8LitCIiIiIiMjMUoRGRERERGSazfAfvbwXFKEREREREZGZpQiNiIiIiMi0U4RmIkVoRERERERkZilCIyIiIiIyxQw95ewoitCIiIiIiMjMUoRGRERERGTaKUIzkSI0IiIiIiIysxShERERERGZcuYK0UyiCI2IiIiIiMwsRWhERERERKaZo9/QHEERGhERERERmVm6oBERERERkZmlW85ERERERKac/rDmZIrQiIiIiIjIzFKERkRERERk2ilCM5EiNCIiIiIiMrPMp/CP9Hzf9zb9wx85BcDz/QU+1X49n7z2GABfWH+A/oUF5i8EFi8mABYu9mhsbMOVGwCkrS282x21Z80m4cQJWDkBwOD0Ep37mnTWAp3TBsDu6QRrXU6t7gDw2MmrPL64wXe01gF4fbnJ/bHD6ZiDWnPWIFq+HmynHgA73udyFVivFgH4Rv8UX+uu8fXOKgDnb55kc2eRre25epwlxVak3DYa23ms5bbT2Ek0tvO+FTt94s0+4eZu3pdOF9/tQr1/3uvhgwFeVbmB8c8zxLxNWWBFgTUaOb9RYo0G3sppbzbwVkHVyvtWtWK9GINWfn8GTaNqGVUzN1E1ITWhauX+qobjTccbqX7PK4rGgEajYq7Rz+9Z2Weu6LNQ5rHPF31OlLvMhfz+LRZdFuMu83V6IXSZD11a1qdluY1W6NfpvL8liZYlyjxMIlCaUdafTcQIBKLlV4BArjz8/I6r8jRaTziJNFaW01X93yfJnQof1ajcqWAsndcrjMrzePoEkhtVPb4Ko++Rqh538kDPI6lO520DfS9G29xSxwMVgb7HUXmFkTyX9z1SeSDVbeV9M/ppvF+rxzWeDvR9b1zJrW7DbskbbyONlzOe3nv14Tr7t/HD6o6lh3VuTe9te2gd2Fe2v+7R+ePj2jeVHujvsL6Y0N54xfFtb21gfxvDdh55+AoAb177Cm9d+jJPlDn9UNGkaSVd77NR5WPwhf4yf9J5hOdePgfAFy/fz9b6Es2Nep7bgIWNirnNfEyWV3aw61ukrW1Sp7PXqRlhLs9rtrAAy4ukkwsAdE+16K4UdFbz96W7Ar2VRLUyYP5kbuOB5W3OLl7nkbmrAJxrXuFMeZUHYp6PV0PFUiiYszxnDY/dyhNdHwB5/t1OztWUJ6nL1RKXBye42FsBYL13gs3uEpc7eX6+3p5jp92k385tWjsSbwaKjlG0864VbYgdp+zkN77oOEUnUXRyn6EzIHQH2G6en6zXh14f7/Whn98z7w/wwQDqOdqTQ6qYyAwsYDFisZ6jYsTKAmKsB5bndIqc9rrMy6JOR7wMeBlJZX2cFkYqA17Ux09ppMKoSvbKC/Di1nSq8zxS59XzXJHzPOa0F3l9WE5wKByLjsX63BCdEBKx3ibGRAyJItZzep0uQ66f1yuKOt0IA4qQKCxRhHqber20+rwZKkrLC0Aw35eOliitItSvAJG8Hus2AoloTmmDutyJlgj1LB4tEfG6XhrVCbZ3XoikfXmxPoCHr8H20mHs4I5jP5QY1d37hhDHDvt9+fvq7J8bDjvbRQ7UObDNUXX32j36PHpwHEe5XVuTtzt+H4d509Pnee4z3Ttr5B5YWDvj3/VD/9M96euPP/B3nnP3p+5JZ3eJIjQiIiIiIjKz9BsaEREREZFpN303VU0NRWhERERERGRmKUIjIiIiIjLNXH+H5iiK0IiIiIiIyMxShEZEREREZNopQjORIjQiIiIiIjKzFKEREREREZlihn5DcxRFaEREREREZGYpQiMiIiIiMu1cIZpJFKEREREREZGZpQsaERERERGZWbrlTERERERkyumhAJMpQiMiIiIiIjNLERoRERERkWnm6A9rHkERGhERERERmVmK0IiIiIiITDlLr/YIppciNCIiIiIiMrMUoRERERERmXb6Dc1EitCIiIiIiMjMUoRGRERERGTK6e/QTKYIjYiIiIiIzCxd0IiIiIiITDMH3O/NcgfMbNXMPmZmL9SvKxPqVWb26Xr50Fj+o2b2qXr73zazxnH61QWNiIiIiIjcDe8DPuHubwQ+UacP03H3J+vlr43l/33gV+vtrwM/dZxOdUEjIiIiIjLlzO/Ncod+GPhAvf4B4F3H3j8zA94O/Ktvdntd0IiIiIiIyN1wv7tfAqhf75tQr2Vmz5rZH5nZ8KLlFHDD3Qd1+jzwuuN0an6H98p9K5z57mX/7d89BcDjZZeVOE/fKwA2qg5f6K3wyZtv5JNXHwXgxfXT2Pk55i8aAIsXE/MXdyk3tnKD126Qtnbwfi+nzQhzc4QTS/jqMgD90wt0Tjdon87XeLtrxu7pirDWBeCB1S0eW77Cdy5s5HG1LnGmvMpDscvJkB8WN2cNogUqz3/KteM9ttOAyymXXxws8/X+Kb7ezfv21fYpLrVPsLm9yM3tVh7bVkmxFSi38740tqHcdho7uc1yp6Lc7hNv5n2xdhfrdPHdXQC828N7Pbw/gFTtf2Mtt2kxQoxYkcdljQbWbEAz36bozQbeKvFmSdXKdaq5SNUMDFq5jUErUDWhqtNVs15a+ftUNSA1ndRM0MhjD82KolHRaOTv6Vyjz3zZp1X08+dWdpkveiwWed8WYpfF2GU+dpkPdV7oMh+6LIT8ubSsXy+5zdISLaso64e1lwYNMwJQWv5sI0YgEOv3IxAI2Ohtinb86/zhZw2QcBJprGwvXeEkd6p6XKkur+r1XL/Or8fS90CFkbx+jzH6HkflFYHkgZ5HUv1/E7lOQeV76WGd3G+g8kC/Tg/bGLYN5LQH0rCfuv7eOALJbV96kCIJo6rzktd1Rm3YKC+Pw/a1kYblHMwz3Pc+m4PlPtbGKK9+HRqv46Nt2Zf2sTZh71H/B8vz+uFl41PpYfU5MKbxfvYKDtlulHFr2wcb+c5f2aZz7iQAW+cKts9BdTbPDY+/boO3nHqJNy+8wOPlywDcH+coLdJO+fi6VPV4vr/GszcfA+BPb5zhhStrdNYXAWitR+Y2nIXNitZmPgaLy9twYxvf3gYgdbt58CF/n8Jci7C0iJ/IbVSrC3RXmuyuRnZX8/e0uwK9lYSv1HPByTYPLm1zdvE6AI/OXeFc8wqvK67X497hVHQWraRpeY4aHrfDc0XX+7S94kZ9gF2rWmxWS6wP8vuz2T/BeneZ9d0lAK7uLnCjPcfNdpP+zRIAa0diO1C083tedKBoQ9Gu55eOU+wmYid3UrQr4u4A6/ax3bwv1utDt4f3c5peHx8M8Kqen6sqrx91LjbL83a9jxZDnsPL+kGlRZHn82KYjngRoSzwMn8OHiNehlE6lYFUGKnMbaaG5XRRHwsFdXleB/DC6vxhGlLMr3kbxyPUUwleeK4bHS/q/QsO0bEi1fvihOCEmNMxJmJMFKE+b4REOZYuQqKMFdESjZjfw8IqipAo6j+j3owDCkuUYa88mFNaTpdWUYaKwFheGBDH0sESkTRKR0sEEo195T7KH9aJ+K3pelxxmF8ftMM29ucdSA/Lx/7bPI4d9MOzVRybFg6eweKozv6547AzXeRAnQPbHFV3f9uTz6MHx3GUo9o5ervj9/Gmp8/z3Ge6x9/gVbK4csaffNv/cE/6+vcf/LmvAVfGsp5x92eGCTP7OPDAIZv+IvABdz85Vve6u9/yOxoze8jdL5rZY8D/C/wAsAV80t3fUNc5A3zE3b/ndmPWY5tFRERERGToirs/NanQ3X9wUpmZbZjZg+5+ycweBDYntHGxfn3JzP4t8J8C/xo4aWZFHaV5GLh4nAHrljMREREREbkbPgS8p15/D/A7ByuY2YqZNev1NeCtwBc83zb2B8CPHrX9YXRBIyIiIiIyxYyZeSjArwDvMLMXgHfUaczsKTP7tbrOfwI8a2afIV/A/Iq7f6Eu+3ngb5vZi+Tf1Pz6cTrVLWciIiIiInLH3P0q+fcwB/OfBX66Xv8PwKG/i3H3l4Dv/2b71QWNiIiIiMg0uwt/9PLbmW45ExERERGRmaUIjYiIiIjIlLsLv2/5tqUIjYiIiIiIzKzbXtCY2fvNbNPMPjeW90tmdsHMPl0v75yw7dNm9iUze9HM3nc3By4iIiIi8prh92iZQceJ0PwG8PQh+b/q7k/Wy0cOFppZBP4x8FeBJ4B3m9kTdzJYERERERGRcbe9oHH3PwSuvYK2vx940d1fcvce8C+BH34F7YiIiIiIvKbNyN+heVXcyW9ofsbM/qy+JW3lkPLXAd8YS5+v80RERERERO6KV3pB838ArweeBC4B//CQOnZI3sTrPjN7r5k9a2bP7lzrvcJhiYiIiIh8m3Eg+b1ZZtAruqBx9w13r9w9Af+Uw/+i53ngzFj6YeDiEW0+4+5PuftTi6uNVzIsERERERF5jXlFFzRm9uBY8keAzx1S7Y+BN5rZo2bWAH4c+NAr6U9ERERE5DVNTzmb6LZ/WNPMfgv4y8CamZ0H/hfgL5vZk+Td/irwt+q6DwG/5u7vdPeBmf0M8FEgAu93989/S/ZCRERERERek257QePu7z4k+9cn1L0IvHMs/RHglkc6i4iIiIjI8c3qE8juhTt5ypmIiIiIiMirShc0IiIiIiIys257y5mIiIiIiLzKXPecTaIIjYiIiIiIzCxFaEREREREppweCjCZIjQiIiIiIjKzFKEREREREZlmM/xHL+8FRWhERERERGRmKUIjIiIiIjLFDDA95Wwi8yl8c+bvP+P3/8L/mNcf3eJND32NHzj5BQD+s9Y3eLho0rSSnbQLwNcGznO7Z/ij7TcA8OzmGS5fOEnrQgnAwkVn8eKA1sU2APHyDdL1G6R2e/QIPCsKwvw8trIMQLV6gu59c3RO52u+9n2B3TWnvzbIba61ObtynTcsXebx+XUA3thY50zxMqdjbnMpNGhaOdqvvlfspC43UgJgo5rjwmCFr/XW+OruKQDOt09y6eYJrm0tANDbahK2I+V2DqaV29DYcho7uY/GdqLcGVDs9AEI7R7W3oXOLt7tAeDdLt4f4INc55bH/plhRYnF3Ic1GtAosWYTGnn83mrgzZJqLqdTKzJoRapW3qZqGoOWUTVzk4OWUbUgNaBq5f6qBqRmwht1/82K2KxoNPJ72iwHtBp95ss8zoWyx3zRYyH2WCi6ACzGLouxy3zM6fnQYyF0WQg53bL+aMnpAaUlWlZRWu62BKIZJTkjmFESiVan68BlqMujHT+QWXkaraex2HAiUbmT2CuvcJI7VV0vAZU71Wgb6DtU9TgqNxI2Svc9UGGk+jXnFVQYlecx94lUHkj1PlUe6HukGqWt3iaQvO6HXCfVbQz76HsctZHG+khuVAQGKYzaTZ63SeNj970+8vY26iPV+5a3s0PbGJYNy31sm9H77Jbzx9qAvSj9sPzW+nufoR9Wh/3l+1/359+6PjmPSdtwa/m+7fZV2tv+O/77z+PdfCxY2SCurVI9fBqA7Ufm2ToXuXm2YvHsFgDf98B5/vPlF/i+1tcAeLRMLIe50fd4K+3y0qDgs92HAfiTnXN8+urDXNg8ia23AJjbMOY3nPnNfMw1NzvEa1v4y7mPtHMTHwxG47SyQViYw5aWSMuLAAxOzbG72mB3JX8fdleN3orTW8lHQ3Gyx6mTOzy8dAOAc/PXeKR1lTONqzxUXAfgdOhyMgTmQ56jxudegK73aac+2/W+3UgF16p51gd5zl8fLLPZO8Gl7jKXd/O4rnbm2Wq32G038r7cLAntQNHOn0vRNooOFO38YRQdKDqJsp2Iu7mf2BkQugNCp55/e32s28d7vVHaBwPo53KvEl5V4GnyI1rNwAIW6u9HjFiMEPMxakUBRYEVEYr6/y2LiJcFFLmOlxEvI6ms00UglYFUT5ReGKk0qtJIRX08FUYqwOsmUwGpzHl5G0hxr9wjpMJH+TnP8SIvQL5PJDoU+f2y6ITohJDTISZivQAUIVHERAyJsq4TQ6IRKmKdboSKIlQUdbqwRBkqCsvpvF5R2l6d0iqiJUqrRukwlo44pQ0I9a+yI4nSBkRzYj2vB0tEnFj3E0jEOu/QtCUiOR1s79wQ8VGdXO9Aemw9jpWNn6ni/qljf9n+otG572C9XPdAQ6Mx3Zo/se4xbwaKh7R5J+3dut3h7b/p6fM895nu8Tp/FZ048bA/9Rd/5p709Qcf/4Xn3P2pe9LZXaIIjYiIiIjItEu3r/Japd/QiIiIiIjIzFKERkRERERkyuk3NJMpQiMiIiIiIjNLERoRERERkWmmv0NzJEVoRERERERkZilCIyIiIiIy1Xzyo9xFERoREREREZlditCIiIiIiEw5U4BmIkVoRERERERkZumCRkREREREZpZuORMRERERmXZ6KMBEitCIiIiIiMjMUoRGRERERGSaOVh6tQcxvRShERERERGRmaUIjYiIiIjItNNvaCZShEZERERERGaWIjQiIiIiItNOAZqJFKEREREREZGZpQiNiIiIiMiUM/2GZiJFaEREREREZGYpQiMiIiIiMu0UoZlIERoREREREZlZitCIiIiIiEwzB9KrPYjppQiNiIiIiIjMLEVoRERERESmmOF6ytkRzKfwzTkRTvlbz/wEAL1za7z8+jm2HjMA+o91+K6zl3j72vO8Zf4FAB4vByyHOfpeAXCp6vCF3ik+efMNAPzRlUf58/XT2PkWAPMXjaULFfOXuhQbL+dOr94gbW/jg0FOmxHm5ggnlgDw1WV69y3SOV0C0D4d2V2D7umKeKoLwP2rW7zx5GW+c2EdgDc0N3ikvML9sQfAamjQtIJoOTBWeaLjPW6kAVeq3O56dYKv9tb4evcUAF/vrHLh5jJXdhYAuLnVgq2SYju3UW4bjS1obOfPsbGTKHcqip0+8Wbu19pdrNPFd3fzvnR7eK+H9+t9TdX+D8AMixFixBqNnNUosbKEZk57s4G3SlIrjzs1C6q5SNXM4xrMBQZNo2pB1cyf3aAFqQFVK4+1akBqOqlVx1AbidCoKBp5PM1mn1Y5YL7sM1/mfZkveiyVXRbq93Qu9liMXeZj/gyWwi7zoUsr9AFYCF1a1q+XvL+lJVpWUdZ/oao0aJiNwpWlBSJGqHOi5fWAjd6i4Wd4XJXnfUx1n6mOG1fue+s4yZ1qVCeXDz+dnN6LOPc8kDAqjORWt2H0PVIxTAeSB3oe6zZCXaeo+99LV3UbiUDlgX69zbCNYZt9jzntoa5f9+lhbBx5fTw9SJE0HJcbaax+wg7NG28jDcsZT++V+4HthnV8rM4ob2x937Z1/b26e2XjdWDv75sdLM/rB9M2yj+Yty//kG3G+7q1DvssfWqOky/m7/78S9fh0ibV1lYuNCOePAkPnqZ9bhmArXMFO+cgnesA8J0PbfCW1Zf4iwsvAvBE+TJrcY7S8nehnXpcqnp8vncff9p+BIDnbpzlhc3TdDfmAWitR+Y3nPnN/M1tbXYprmzD9TzX+s5NUrebBx9yu2GuRVhaxJfzfFutzNNdbbK7mst3VwPdFeit5G+/r/RYWu7w4Iktzi1eA+Bc6xrnmlc4U14F4HRocyo6i5bnqPG5F6DvFV3vs53yvHAjBa6lFlerRdYHJwG41DvJRu8Em7uLAFzpLHK9PUe73QRg0C6wdqRo13NF2yja5KVTzy8dp+gkik4ee+xUxN0B1s2fk+32sV4funlO834fen18MMCr+uivqrx+1Pl6OG8DWMBigLLMrwBFgRUFFPX/YxYRLyKUOe1lzEtd38tIKgOpEUhF/d0vjVTYXroY5jFKe3EwDSnm15zneAH19IEXnutHH6UJPkpbkbDohJDTISZivRQh1buSiGEvXcaKIiSi5XQjVhRWjcoboaIMFYUlypDf48IqSqsINjwv5DqB8fSAOJYOlogkSsttREsEEo06nct9NI5AHtOwjfF0qOtEhq++r42hXPdAui6PB/KHht/6uDd13HJ7ThzVsX35k850kQP1Dmw3qd7+to8+jx4cyyttZ/J2uf03PX2e5z7TPV5nr6LlhYf8TU/8rXvS1+8/+0vPuftT96Szu0S3nImIiIiIyMzSLWciIiIiItNuCu+qmhaK0IiIiIiIyMxShEZEREREZNopQjORIjQiIiIiIjKzFKEREREREZlm+sOaR1KERkREREREZpYiNCIiIiIiU05/WHMyRWhERERERGRm6YJGRERERGTaud+b5Q6Y2aqZfczMXqhfVw6p8zYz+/TYsmtm76rLfsPMvjJW9uRx+tUFjYiIiIiI3A3vAz7h7m8EPlGn93H3P3D3J939SeDtQBv4/bEqPzcsd/dPH6dTXdCIiIiIiEy1exSdufPf6fww8IF6/QPAu25T/0eBf+Pu7TvpVBc0IiIiIiJyN9zv7pcA6tf7blP/x4HfOpD398zsz8zsV82seZxO9ZQzEREREZFp5tyN6MlxrZnZs2PpZ9z9mWHCzD4OPHDIdr/4zXRiZg8C3wN8dCz7F4B1oAE8A/w88Mu3a0sXNCIiIiIiMnTF3Z+aVOjuPzipzMw2zOxBd79UX7BsHtHPjwEfdPf+WNuX6tWumf0z4GePM2DdciYiIiIiMu3SPVruzIeA99Tr7wF+54i67+bA7Wb1RRBmZuTf33zuOJ3qgkZERERERO6GXwHeYWYvAO+o05jZU2b2a8NKZvYIcAb4/w5s/5tm9lngs8Aa8HeP06luORMRERERkTvm7leBHzgk/1ngp8fSXwVed0i9t7+SfnVBIyIiIiIy5ezePRRg5uiWMxERERERmVmK0IiIiIiITDtFaCZShEZERERERGbWbSM0ZvZ+4IeATXf/7jrvt4HH6yongRvu/uQh234V2AYqYHDUM61FREREROQQDiRFaCY5zi1nvwH8I+CfDzPc/W8M183sHwIvH7H929z9yisdoIiIiIiIyCS3vaBx9z+snxV9i/qP3vwY8IoesSYiIiIiIrfj+g3NEe70NzT/BbDh7i9MKHfg983sOTOPZhc+AAAR4ElEQVR77x32JSIiIiIiss+dPuXs3cBvHVH+Vne/aGb3AR8zs+fd/Q8Pq1hf8LwXoMX8HQ5LREREROTbiCI0E5kf482pbzn73eFDAeq8ArgAfJ+7nz9GG78E7Lj7/3q7ustzD/qbm+8EoNrawoqCuHYKgMHZ+9h6/QIvPxboPNYD4LFzm7ztvi/zlxafB+CJ8iZrcYHKEwBXU4cv9Jb4VPv1AHzy2mN8cf1+BhfmWbiQg1QLFxOLF7uU69t5EFevk17exvu90bhCq4UtLeXE6jKDtUU69zVpn85t7K4Zu6cTnO4CcHp1m8eWr/L44gYAj7cu8Uh5hYeKTm4iFMxZg2hhNNauD3g59biWIgAXBie4OFjhK93TAHy9s8r5myfZ3F4EYGenRdoqKbdy/XLLKHeg3HYaO7nNxnai2OlT7OR9sXYX63Tx3TxO393Fez28P8j75mnvoDGrXwNWFliRr4Gt0YBGmV8BbzXwZgNv5fKqVVC1Yr3kNgYtY9C0Ubpq1ksrd5GaTtVwvJn79kbCmhVFY0CjUQEw1+gzV/aZL/O+zBc9Fssui0VOL8Qu87HHYtzN5aHHQugyH7q0rA9Ay/q0Qn8sXVGSaFl+v0qDCJT1vpcWiBiBQKzzAoGAjb4b0b65YOfw8044iTSWv5eucJI7FV7XzeVVXTen69d6LH0PVBjJ6/cYo8Loe6zTgeSBXp1O5PqVB/pejLa5pY4Hqjqg2/dIqvsBSB7oe6TyQKrzhuv9NN7v+LhyejAcl+c+k9tYG3t5eRy2r400LGc8vVcO4HV749v4WPmwvo+lh9sdrD/8LaYfUgdgfCb1A/34hG3Hp9/D6nNgX8aNNh3L/5kn/4D/59JfAOClFx9g8cWClRfzcb3w4hZ2YYPqxo1RB/HECbh/je7ZFQC2zjXYfgR6Z/Px9OjDl3nz2ld482IOwj9RXuGhoknTSrqej5+NqsvzvRX+tPMIAM+9fJbnr9zH9nqeK1vrBXMbzvxm/l7PbXQpL+/AjS18eye/h51OHtPw+JqbwxYWYDnPc2llke5qk93V/B3dXQl0V6C3mqhW6v072eH+E9ucXbwOwCNzVznXvMKZ8ioAD8QdVkPFUshtDOfeocoTXR+w43226w/7ampyuVpivX8y72t/mfXeCTa7ed8udxa53p5jp90EoN9uYO1IvBko2nlfig4UbYid3GbZcYqOU3RSXT4gdAaEbt4P2+1j3R70B3g3z9EMBnh/gA/qObqq8Ko6+h83ZnnejvkYsxggRqys/x8zRij25nSKiJdFzge8LPAy4mXAy3ouKAOpMFKZ3zcvjFQaqaiP2ZJcXjfpxV66nl7yemSsjo/yADw6XuT8YZrhAlh0LCYsOjGmelcSITgx1O9prChjGqXLkChjRazn+CIkGmFAERLFKK+itEQR8gw7XC9tmK4oQ0Woj7zScnulVYTRuaMikkbbREsEEtGG2wyI+GgcuSwRcUI974/StndeiOQ8gGB767nMCXX7ozr167Df8bJcXueNTSkHz2BxVGf/vDPpTBc5UO/AdpPq7W978nn04DiOclQ7h3nL0xd47jPd43fwKlluPeBvOfMT96Sv33vxHzw3aw/yupNbzn4QeH7SxYyZLZjZ0nAd+CvA5+6gPxERERGR1yb3e7PMoNte0JjZbwGfBB43s/Nm9lN10Y9z4HYzM3vIzD5SJ+8H/p2ZfQb4j8CH3f337t7QRURERETkte44Tzl794T8nzwk7yLwznr9JeB773B8IiIiIiKvbfo7NEe606eciYiIiIiIvGru9ClnIiIiIiLyLeX5oU1yKEVoRERERERkZumCRkREREREZpZuORMRERERmXYz+kjle0ERGhERERERmVmK0IiIiIiITDM9tvlIitCIiIiIiMjMUoRGRERERGTa6Tc0EylCIyIiIiIiM0sRGhERERGRaacIzUSK0IiIiIiIyMxShEZEREREZKq5IjRHUIRGRERERERmliI0IiIiIiLTzIGUXu1RTC1FaEREREREZGYpQiMiIiIiMu30G5qJFKEREREREZGZpQiNiIiIiMi0U4RmIkVoRERERERkZumCRkREREREZpZuORMRERERmWoOSbecTaIIjYiIiIiIzCzzKfyBUfPRh/2x/+bvALD6fMXSl2/ANy4BUG1tYUVBXDvF4Ox9AGy9foGXHwt0HusB8Ni5Td5235f5S4vPA/BEeZO1uEDl+Q8SXU0dvtBb4lPt1/PJa48B8MX1+xlcmGf+Yr7GW7yQWLjUo3FpKw/q6nXS9g7e7Y7GGVotbGkJVpcBGKwt0rmvSft0bmN3zdg9nWAtb3P61DaPLV/l8cUNAB5vXeKR8goPFR1WQw6WzVmDaHvXme3U4+XU41qKAKxXi3yjf4qvdE8D8PXOKhdvLrO+vQTAzk6LtFVSbkXKLQOg3IFy22ns5P1vbCeKnT7FTn6/rN3FOl18N4/Td3fxXg+qCq+qPJCD35MQsbLAijxuazSgUeZXwFsNvNnAWwVVK9epWrFe8rgGLWPQtFG6auYlNanrO1XD8abjjTx2a1YUjQGNRh7XXKPPXNlnvsz7Ml/0WCy7LBY5vRC7zMcei3GX+VDnhS7zoUvL+gC0rE8r9MfSFSWJluU+S4MIlGaU9WcTMQKBaHnsgUDARm/P+Gd4O8PvJUDCSaSxsr10hZPcqfC6bi6v6vVcv86vx9L3QIWRvH6PMSqMvsc6HUge6Hkk1f+/UWFUHuh7MUoP6+R+A5UHqrp+3yNp1M9eXuWBVI9juN5P4/2OjyunBx6p6rzkdZ1RGzbKy+OwfW2kYTkH8/Y+F6/bGy/3sfJhfR9Lj7YbW89l7Ev7WJsA40eMH+jHJ2w7fpgdVp8D+zLOgS/9l+8n1T2/2O/y0ZtP8OH178npFx9g8YWSlRcHLLyY5zW7sEF148aog7C0hD1wmu7ZFQC2zjXYPmf0zuW54dzrrvDW0y/x5sUXeKK8AsBDRZOmlXQ9Hz8bVZfneyv8aecRAJ57+SzPX7mP7fU8RzU3CubXnfnNxNxGbre8vAM3tvDtnfwedjp5TMPja24OW1iA5cVcvrJId7XJ7mrB7kr+znVXoLeaqE4OAFhY6XD/iW3OLl4H4JG5q5xrXuFMeRWAB+IOq6Fi6ZC5d3hMdn3AjvfZrj/sq6nJ5WqJ9f7JvK/9ZdZ7J9js5n273FnkenuOnXaTfjvPhdaOxJuBopP3pWjnJXZym2XHKTpO0cl9Fp0BoTMgdAfYbn5PrduD/gDv5TT9Ht4f4IO8r6O5+qjzuRlYwGI+Bi0GiHkeByBGKPbmdIqIlwXE+hXwMuJlwMt6LigDqTBSmd83L4xUGqmoj9mSXF5APZ0ckgaP+TW34aM8AI+OFzl/mCY4FI5Fr/clYdGJMdW7kgjBiaF+T2NFGdMoXYZEGSuiJYo6rxEGFCFR1PN+ESpKSxQhn2uG66UN0xVlqAj4KC9aorSKMDp3VETSvvJAIlr92duAiI/yh3Uifmva9s4LkZwHEGxvfS/vQHpYbj7Wxt768GwVx6aUg2ewOKqzf96ZdKaLY+fDcGCbSfUOCkf8n/vBcRzlqHYA3vL0BZ77TPf4Db5KlovT/uaTP3JP+vro1X/6nLs/dU86u0sUoRERERERkZml39CIiIiIiEw7/YZmIkVoRERERERkZilCIyIiIiIy7abwd+/TQhEaERERERGZWYrQiIiIiIhMM3dI6fb1XqMUoRERERERkZmlCI2IiIiIyLTTb2gmUoRGRERERERmliI0IiIiIiJTzvUbmokUoRERERERkZmlCI2IiIiIyFRz/YbmCIrQiIiIiIjIzNIFjYiIiIiIzCzdciYiIiIiMs0cSLrlbBJFaEREREREZGYpQiMiIiIiMu1cj22eRBEaERERERGZWYrQiIiIiIhMMQdcv6GZSBEaERERERGZWYrQiIiIiIhMM3f9huYIitCIiIiIiMjM0gWNiIiIiMiU8+T3ZLkTZvbXzezzZpbM7Kkj6j1tZl8ysxfN7H1j+Y+a2afM7AUz+20zaxynX13QiIiIiIjI3fA54L8G/nBSBTOLwD8G/irwBPBuM3uiLv77wK+6+xuB68BPHadTXdCIiIiIiEw7T/dmuZMhun/R3b90m2rfD7zo7i+5ew/4l8APm5kBbwf+VV3vA8C7jtOvLmhEREREROReeR3wjbH0+TrvFHDD3QcH8m/L3KfvmdZmtg3c7upOXhvWgCuv9iBkKui7IEP6LgjoeyB77uS7cM7dT9/NwXwrmNnvkffzXmgBu2PpZ9z9mbGxfBx44JDtftHdf6eu82+Bn3X3Zw9WMrO/DvxX7v7Tdfq/JUdtfhn4pLu/oc4/A3zE3b/ndgOe1sc2f8ndJ/6QSF47zOxZfRcE9F2QPfouCOh7IHteC98Fd3/61R7DkLv/4B02cR44M5Z+GLhIvig9aWZFHaUZ5t+WbjkTEREREZF75Y+BN9ZPNGsAPw58yPNtY38A/Ghd7z3A7xynQV3QiIiIiIjIHTOzHzGz88CbgQ+b2Ufr/IfM7CMAdfTlZ4CPAl8E/i93/3zdxM8Df9vMXiT/pubXj9PvtN5y9sztq8hrhL4LMqTvggzpuyCg74Hs0XdhSrj7B4EPHpJ/EXjnWPojwEcOqfcS+fc035SpfCiAiIiIiIjIceiWMxERERERmVlTd0FjZk+b2ZfM7EUze9+rPR751jKz99v/3979hGpRxWEc/z7cLKMi0zJCDQtc6KKsRQi2MIvoj2QLA6NIQnDTwqCIahMFLtpkRNGmIov+iUVJq0SN2mRpWhoGWUiJ4l34pyIwqqfF/F57vV3Ehfe+73vn+cDlnXNmFgfmucycmXPOSMOS9nTVTZW0SdIP9XtJ1UvSC5WNbyVd37uWx9kkaZakrZL2SvpO0uqqTxZaRtJkSV9K+qay8HTVXyVpW2XhvZpIiqTzqryv9s/uZfvj7JI0JGmnpI+rnBy0lKT9knZL2iVpe9XlGhFAn3VoJA0BLwG3A/OAeyXN622rYoy9DoxcivBxYLPtOcDmKkOTizn1twp4eZzaGGPvL+AR23OBBcBD9b+fLLTPCWCx7WuB+cBtkhYAzwJrKwtHgZV1/ErgaH23YG0dFxPHappJwx3JQbvdZHt+1xLNuUYE0GcdGppJQPts/2T7T+BdYGmP2xRjyPZnwJER1UuBdbW9Dri7q/4NN76gWav8ivFpaYwl24dsf13bv9HcwMwgWWidOqe/V3FS/RlYDGyo+pFZ6GRkA3CzJI1Tc2MMSZoJ3Am8UmWRHMSpco0IoP86NDOAX7rKB6ou2uVy24egudEFpld98tECNVTkOmAbyUIr1TCjXcAwsAn4EThWS33Cqef7ZBZq/3GapT5j8D0PPAb8U+VpJAdtZuATSTskraq6XCMC6L9lm0d7mpJl2KIj+ZjgJF0IvA88bPvX0zxgTRYmMNt/A/MlTaFZ/nPuaIfVb7IwAUlaAgzb3iFpUad6lEOTg/ZYaPugpOnAJknfn+bY5KFl+u0NzQFgVld5JnCwR22J3jnceTVcv8NVn3xMYJIm0XRm3rL9QVUnCy1m+xjwKc28qimSOg/hus/3ySzU/ov5/zDWGDwLgbsk7acZfr6Y5o1NctBS9R0TbA/TPOi4gVwjovRbh+YrYE6tYnIusBzY2OM2xfjbCKyo7RXAR131D9TqJQuA451XzTHYaqz7q8Be28917UoWWkbSZfVmBknnA7fQzKnaCiyrw0ZmoZORZcAW5wNrA8/2E7Zn2p5Ncy+wxfZ9JAetJOkCSRd1toFbgT3kGhGl7z6sKekOmqcwQ8Brttf0uEkxhiS9AywCLgUOA08BHwLrgSuBn4F7bB+pm94XaVZF+wN40Pb2XrQ7zi5JNwKfA7v5b7z8kzTzaJKFFpF0Dc3k3iGah27rbT8j6WqaJ/VTgZ3A/bZPSJoMvEkz7+oIsLy+NB0TRA05e9T2kuSgneq8d74+fw7wtu01kqaRa0TQhx2aiIiIiIiIM9VvQ84iIiIiIiLOWDo0ERERERExsNKhiYiIiIiIgZUOTUREREREDKx0aCIiIiIiYmClQxMREREREQMrHZqIiIiIiBhY6dBERERERMTA+hdM1pEBHA8lqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "plt.imshow(mm.numpy(), aspect = 'auto')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2, 2, 2, 3],\n",
       "         [1, 2, 3, 4],\n",
       "         [3, 0, 1, 0]],\n",
       "\n",
       "        [[2, 0, 1, 4],\n",
       "         [1, 3, 2, 1],\n",
       "         [0, 1, 0, 2]],\n",
       "\n",
       "        [[1, 2, 2, 2],\n",
       "         [0, 4, 0, 0],\n",
       "         [2, 3, 2, 2]],\n",
       "\n",
       "        [[4, 0, 0, 0],\n",
       "         [2, 2, 1, 2],\n",
       "         [4, 0, 0, 4]],\n",
       "\n",
       "        [[2, 3, 0, 2],\n",
       "         [4, 1, 3, 3],\n",
       "         [4, 0, 1, 2]]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 5\n",
    "seq_len = 3\n",
    "emb_dim = 4\n",
    "arr1 = torch.randint(low =0, high = 5, size = (bs, seq_len, emb_dim))\n",
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  1.0000,  1.0000],\n",
       "        [ 0.8415,  0.0998,  0.5403,  0.9950],\n",
       "        [ 0.9093,  0.1987, -0.4161,  0.9801]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2 = positional_encoding(emb_dim, seq_len)\n",
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0000,  2.0000,  3.0000,  4.0000],\n",
       "         [ 1.8415,  2.0998,  3.5403,  4.9950],\n",
       "         [ 3.9093,  0.1987,  0.5839,  0.9801]],\n",
       "\n",
       "        [[ 2.0000,  0.0000,  2.0000,  5.0000],\n",
       "         [ 1.8415,  3.0998,  2.5403,  1.9950],\n",
       "         [ 0.9093,  1.1987, -0.4161,  2.9801]],\n",
       "\n",
       "        [[ 1.0000,  2.0000,  3.0000,  3.0000],\n",
       "         [ 0.8415,  4.0998,  0.5403,  0.9950],\n",
       "         [ 2.9093,  3.1987,  1.5839,  2.9801]],\n",
       "\n",
       "        [[ 4.0000,  0.0000,  1.0000,  1.0000],\n",
       "         [ 2.8415,  2.0998,  1.5403,  2.9950],\n",
       "         [ 4.9093,  0.1987, -0.4161,  4.9801]],\n",
       "\n",
       "        [[ 2.0000,  3.0000,  1.0000,  3.0000],\n",
       "         [ 4.8415,  1.0998,  3.5403,  3.9950],\n",
       "         [ 4.9093,  0.1987,  0.5839,  2.9801]]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1+arr2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
